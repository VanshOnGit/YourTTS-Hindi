{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SECS-YourTTS-EN_(VCTK+LibriTTS)-PT-FR (Experiment 4)",
      "provenance": [],
      "collapsed_sections": [
        "MpYNgqrZcJKn",
        "smvc4NpR7DKL",
        "vgQ1ZILTZRcn",
        "GNeWrpUKaUqR",
        "dV6cXXlfi72r"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZK6UdwSFnOO"
      },
      "source": [
        "# **Download and install Coqui TTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvb0pX3WY6MN",
        "outputId": "2a3d3d42-b779-4e46-8add-b0f62153d158"
      },
      "source": [
        "import os\n",
        "\n",
        "! rm -rf TTS/ Coqui-TTS/\n",
        "!git clone https://github.com/Edresson/Coqui-TTS -b multilingual-torchaudio-SE TTS\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Coqui-TTS'...\n",
            "remote: Enumerating objects: 20301, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 20301 (delta 25), reused 29 (delta 15), pack-reused 20257\u001b[K\n",
            "Receiving objects: 100% (20301/20301), 132.67 MiB | 26.41 MiB/s, done.\n",
            "Resolving deltas: 100% (14748/14748), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB9nl2UEG3SY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f3680d6-f8fe-4d91-ef43-bd7062fd9703"
      },
      "source": [
        "os.chdir('TTS')\n",
        "# install requeriments\n",
        "!apt-get install espeak \n",
        "!pip install -r requirements.txt\n",
        "!pip install -q torchaudio==0.9.0\n",
        "!python setup.py install\n",
        "!python setup.py develop\n",
        "os.chdir('..')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  espeak-data libespeak1 libportaudio2 libsonic0\n",
            "The following NEW packages will be installed:\n",
            "  espeak espeak-data libespeak1 libportaudio2 libsonic0\n",
            "0 upgraded, 5 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 1,219 kB of archives.\n",
            "After this operation, 3,031 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libportaudio2 amd64 19.6.0-1 [64.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsonic0 amd64 0.2.0-6 [13.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 espeak-data amd64 1.48.04+dfsg-5 [934 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libespeak1 amd64 1.48.04+dfsg-5 [145 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 espeak amd64 1.48.04+dfsg-5 [61.6 kB]\n",
            "Fetched 1,219 kB in 1s (1,117 kB/s)\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 155047 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1) ...\n",
            "Selecting previously unselected package libsonic0:amd64.\n",
            "Preparing to unpack .../libsonic0_0.2.0-6_amd64.deb ...\n",
            "Unpacking libsonic0:amd64 (0.2.0-6) ...\n",
            "Selecting previously unselected package espeak-data:amd64.\n",
            "Preparing to unpack .../espeak-data_1.48.04+dfsg-5_amd64.deb ...\n",
            "Unpacking espeak-data:amd64 (1.48.04+dfsg-5) ...\n",
            "Selecting previously unselected package libespeak1:amd64.\n",
            "Preparing to unpack .../libespeak1_1.48.04+dfsg-5_amd64.deb ...\n",
            "Unpacking libespeak1:amd64 (1.48.04+dfsg-5) ...\n",
            "Selecting previously unselected package espeak.\n",
            "Preparing to unpack .../espeak_1.48.04+dfsg-5_amd64.deb ...\n",
            "Unpacking espeak (1.48.04+dfsg-5) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1) ...\n",
            "Setting up espeak-data:amd64 (1.48.04+dfsg-5) ...\n",
            "Setting up libsonic0:amd64 (0.2.0-6) ...\n",
            "Setting up libespeak1:amd64 (1.48.04+dfsg-5) ...\n",
            "Setting up espeak (1.48.04+dfsg-5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (0.29.24)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.1.4)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (3.6.4)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2.1.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.42.1)\n",
            "Collecting librosa==0.8.0\n",
            "  Downloading librosa-0.8.0.tar.gz (183 kB)\n",
            "\u001b[K     |████████████████████████████████| 183 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (3.2.2)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.1.5)\n",
            "Collecting pypinyin\n",
            "  Downloading pypinyin-0.42.1-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 39.6 MB/s \n",
            "\u001b[?25hCollecting pysbd\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (3.13)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (1.4.1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (0.10.3.post1)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (4.62.3)\n",
            "Collecting numba==0.53\n",
            "  Downloading numba-0.53.0-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 27.5 MB/s \n",
            "\u001b[?25hCollecting umap-learn==0.5.1\n",
            "  Downloading umap-learn-0.5.1.tar.gz (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.5 MB/s \n",
            "\u001b[?25hCollecting anyascii\n",
            "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 45.6 MB/s \n",
            "\u001b[?25hCollecting coqpit\n",
            "  Downloading coqpit-0.0.14-py3-none-any.whl (13 kB)\n",
            "Collecting mecab-python3==1.0.3\n",
            "  Downloading mecab_python3-1.0.3-cp37-cp37m-manylinux1_x86_64.whl (487 kB)\n",
            "\u001b[K     |████████████████████████████████| 487 kB 48.1 MB/s \n",
            "\u001b[?25hCollecting unidic-lite==1.0.8\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4 MB 49 kB/s \n",
            "\u001b[?25hCollecting gruut[cs,de,es,fr,it,nl,pt,ru,sv]~=1.2.0\n",
            "  Downloading gruut-1.2.3.tar.gz (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 12.7 MB/s \n",
            "\u001b[?25hCollecting fsspec>=2021.04.0\n",
            "  Downloading fsspec-2021.10.0-py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 36.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r requirements.txt (line 6)) (2.1.9)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r requirements.txt (line 6)) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r requirements.txt (line 6)) (0.2.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r requirements.txt (line 6)) (1.5.1)\n",
            "Collecting llvmlite<0.37,>=0.36.0rc1\n",
            "  Downloading llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.53->-r requirements.txt (line 18)) (57.4.0)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.4.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 37.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile->-r requirements.txt (line 14)) (1.14.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->-r requirements.txt (line 16)) (3.7.4.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 14)) (2.20)\n",
            "Collecting Babel~=2.8.0\n",
            "  Downloading Babel-2.8.1-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 21.1 MB/s \n",
            "\u001b[?25hCollecting gruut-ipa~=0.9.0\n",
            "  Downloading gruut-ipa-0.9.3.tar.gz (34 kB)\n",
            "Collecting jsonlines~=1.2.0\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting num2words==0.5.10\n",
            "  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 10.9 MB/s \n",
            "\u001b[?25hCollecting python-crfsuite~=0.9.7\n",
            "  Downloading python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     |████████████████████████████████| 743 kB 50.5 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_de~=1.2.0\n",
            "  Downloading gruut_lang_de-1.2.tar.gz (9.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 26.3 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_sv~=1.2.0\n",
            "  Downloading gruut_lang_sv-1.2.tar.gz (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 35.4 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_fr~=1.2.0\n",
            "  Downloading gruut_lang_fr-1.2.1.tar.gz (12.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.1 MB 11.5 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_es~=1.2.0\n",
            "  Downloading gruut_lang_es-1.2.tar.gz (15.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.2 MB 124 kB/s \n",
            "\u001b[?25hCollecting gruut_lang_ru~=1.2.0\n",
            "  Downloading gruut_lang_ru-1.2.tar.gz (16.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.9 MB 150 kB/s \n",
            "\u001b[?25hCollecting gruut_lang_it~=1.2.0\n",
            "  Downloading gruut_lang_it-1.2.tar.gz (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 27.1 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_cs~=1.2.0\n",
            "  Downloading gruut_lang_cs-1.2.tar.gz (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 12.1 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_nl~=1.2.0\n",
            "  Downloading gruut_lang_nl-1.2.tar.gz (7.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4 MB 18.7 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_pt~=1.2.0\n",
            "  Downloading gruut_lang_pt-1.2.tar.gz (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 27.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words==0.5.10->gruut[cs,de,es,fr,it,nl,pt,ru,sv]~=1.2.0->-r requirements.txt (line 26)) (0.6.2)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from Babel~=2.8.0->gruut[cs,de,es,fr,it,nl,pt,ru,sv]~=1.2.0->-r requirements.txt (line 26)) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from jsonlines~=1.2.0->gruut[cs,de,es,fr,it,nl,pt,ru,sv]~=1.2.0->-r requirements.txt (line 26)) (1.15.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->-r requirements.txt (line 6)) (1.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->-r requirements.txt (line 6)) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->-r requirements.txt (line 6)) (21.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->-r requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->-r requirements.txt (line 2)) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->-r requirements.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r requirements.txt (line 15)) (3.17.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa==0.8.0->-r requirements.txt (line 6)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa==0.8.0->-r requirements.txt (line 6)) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa==0.8.0->-r requirements.txt (line 6)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa==0.8.0->-r requirements.txt (line 6)) (3.0.4)\n",
            "Building wheels for collected packages: librosa, umap-learn, unidic-lite, gruut, gruut-ipa, gruut-lang-cs, gruut-lang-de, gruut-lang-es, gruut-lang-fr, gruut-lang-it, gruut-lang-nl, gruut-lang-pt, gruut-lang-ru, gruut-lang-sv, pynndescent\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201395 sha256=33135c840c27aa89791f605ca67f15fb518df5f06c1aefb955ab6d65fa27cd7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/1e/aa/d91797ae7e1ce11853ee100bee9d1781ae9d750e7458c95afb\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-py3-none-any.whl size=76564 sha256=eb4bcb0c057fcbcce303eb78a9661cc88d9c1629cf119719a2999776df1c57a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/e7/bb/347dc0e510803d7116a13d592b10cc68262da56a8eec4dd72f\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658836 sha256=76b393b1e42217ab97dd6ec5a985d725667b65aacdb963e62f72d78f6daee448\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/69/b1/112140b599f2b13f609d485a99e357ba68df194d2079c5b1a2\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-1.2.3-py3-none-any.whl size=11091278 sha256=dfc9a67ed0db9262a200588c0b54b64ab12d5805c76e1b2f14ea44af3339fa91\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/b4/52/94a0c0762e55a284000bc16c089a4239c600749a5b9f0f31ad\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.9.3-py3-none-any.whl size=39001 sha256=6220fe7ae49bf74da53f29f084ec07ef900d7a6868f77de78e76d3696b867557\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/54/14/3e4f28f11774f67536576662cb932b3cac8428e26be86b3410\n",
            "  Building wheel for gruut-lang-cs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-cs: filename=gruut_lang_cs-1.2-py3-none-any.whl size=5796595 sha256=94437e1ce194d75ffa6f992d8ac44a50489b529af3a37d5be7c8a1215f35e345\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/c6/7a/44b8bab3aedb5b889ef425c2e516019c7e9e9869125d3c2dc6\n",
            "  Building wheel for gruut-lang-de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-de: filename=gruut_lang_de-1.2-py3-none-any.whl size=9574679 sha256=9bf2cc90a183aafe0eae8f3bfe1ea8782b584a3be93b27381fa45e7d82ade7ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/1f/2c/a23ce1aac2c09cf617df745642d280e0be6f894862f63c05b4\n",
            "  Building wheel for gruut-lang-es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-es: filename=gruut_lang_es-1.2-py3-none-any.whl size=15403815 sha256=bf054917bffa4b8deb758bf4d617bbba3449e323c01235176b10a9ed473289e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/57/11/d4a2445ff6dd3a228db36548f95c1f763d3defbff2b7fcdb85\n",
            "  Building wheel for gruut-lang-fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-fr: filename=gruut_lang_fr-1.2.1-py3-none-any.whl size=12103216 sha256=1564a9d530d3996d22158cc6cc84de5bf52e4200016660db0aa00c2b2c9e412e\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/62/e7/e103446f6db651133ac6871bfe0a6a582f00a74a1f0c44ca2f\n",
            "  Building wheel for gruut-lang-it (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-it: filename=gruut_lang_it-1.2-py3-none-any.whl size=1944818 sha256=726ce78edec903067c6a00b246ee5b44644f968aacc29013bdbdd36144ba3535\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/f4/2d/0dc17ee06d958a37a6a873d7ba15bb90f710e307941dc8928f\n",
            "  Building wheel for gruut-lang-nl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-nl: filename=gruut_lang_nl-1.2-py3-none-any.whl size=7399313 sha256=da5b8c4898684009e91059c5489b9243fbab7d54308fb5259b64084a417bb535\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/c0/d8/125b811bf3df62785bffbfdccafe9d414ebc4770a35080669b\n",
            "  Building wheel for gruut-lang-pt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-pt: filename=gruut_lang_pt-1.2-py3-none-any.whl size=3412234 sha256=6c072f85b7aa7801201ef12507d1230a72f8e13e11a0cb510067dd315466b546\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/c6/e2/458765db8d0ded8b33a1fc7551d28e5ae06b450ff5af0a585c\n",
            "  Building wheel for gruut-lang-ru (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-ru: filename=gruut_lang_ru-1.2-py3-none-any.whl size=16955789 sha256=39dd3def01178f5c09596d62882a1793f11465f9b144b58808f276d6c5e96f26\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/36/50/5375078bb647157ed425620b69fc87ba9830161886c600d175\n",
            "  Building wheel for gruut-lang-sv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-sv: filename=gruut_lang_sv-1.2-py3-none-any.whl size=2104835 sha256=063d4b2b464cf170f491c65e490ce1c116d7566a82ffd9a0bf64ccd8670531ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/2c/0b/a087fc907ed77d1dde8df72ab70fffde05ea8bcf06b33b1acb\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.4-py3-none-any.whl size=52373 sha256=ce2aff5f952eff21a009e2ebadfca8b2e2dd7f0387929eb76d14c45bbd37c294\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/5b/62/3401692ddad12324249c774c4b15ccb046946021e2b581c043\n",
            "Successfully built librosa umap-learn unidic-lite gruut gruut-ipa gruut-lang-cs gruut-lang-de gruut-lang-es gruut-lang-fr gruut-lang-it gruut-lang-nl gruut-lang-pt gruut-lang-ru gruut-lang-sv pynndescent\n",
            "Installing collected packages: llvmlite, python-crfsuite, numba, num2words, jsonlines, gruut-ipa, Babel, pynndescent, gruut-lang-sv, gruut-lang-ru, gruut-lang-pt, gruut-lang-nl, gruut-lang-it, gruut-lang-fr, gruut-lang-es, gruut-lang-de, gruut-lang-cs, gruut, unidic-lite, umap-learn, tensorboardX, pysbd, pypinyin, mecab-python3, librosa, fsspec, coqpit, anyascii\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Attempting uninstall: Babel\n",
            "    Found existing installation: Babel 2.9.1\n",
            "    Uninstalling Babel-2.9.1:\n",
            "      Successfully uninstalled Babel-2.9.1\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.8.1\n",
            "    Uninstalling librosa-0.8.1:\n",
            "      Successfully uninstalled librosa-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed Babel-2.8.1 anyascii-0.3.0 coqpit-0.0.14 fsspec-2021.10.0 gruut-1.2.3 gruut-ipa-0.9.3 gruut-lang-cs-1.2 gruut-lang-de-1.2 gruut-lang-es-1.2 gruut-lang-fr-1.2.1 gruut-lang-it-1.2 gruut-lang-nl-1.2 gruut-lang-pt-1.2 gruut-lang-ru-1.2 gruut-lang-sv-1.2 jsonlines-1.2.0 librosa-0.8.0 llvmlite-0.36.0 mecab-python3-1.0.3 num2words-0.5.10 numba-0.53.0 pynndescent-0.5.4 pypinyin-0.42.1 pysbd-0.3.4 python-crfsuite-0.9.7 tensorboardX-2.4 umap-learn-0.5.1 unidic-lite-1.0.8\n",
            "Compiling TTS/tts/layers/glow_tts/monotonic_align/core.pyx because it changed.\n",
            "[1/1] Cythonizing TTS/tts/layers/glow_tts/monotonic_align/core.pyx\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'build-lib' will not be supported in future versions. Please use the underscore name 'build_lib' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'build-dir' will not be supported in future versions. Please use the underscore name 'build_dir' instead\n",
            "  % (opt, underscore_opt))\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating TTS.egg-info\n",
            "writing TTS.egg-info/PKG-INFO\n",
            "writing dependency_links to TTS.egg-info/dependency_links.txt\n",
            "writing entry points to TTS.egg-info/entry_points.txt\n",
            "writing requirements to TTS.egg-info/requires.txt\n",
            "writing top-level names to TTS.egg-info/top_level.txt\n",
            "writing manifest file 'TTS.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE.txt'\n",
            "writing manifest file 'TTS.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating temp_build\n",
            "creating temp_build/TTS\n",
            "copying TTS/model.py -> temp_build/TTS\n",
            "copying TTS/trainer.py -> temp_build/TTS\n",
            "copying TTS/__init__.py -> temp_build/TTS\n",
            "creating temp_build/TTS/speaker_encoder\n",
            "copying TTS/speaker_encoder/losses.py -> temp_build/TTS/speaker_encoder\n",
            "copying TTS/speaker_encoder/speaker_encoder_config.py -> temp_build/TTS/speaker_encoder\n",
            "copying TTS/speaker_encoder/dataset.py -> temp_build/TTS/speaker_encoder\n",
            "copying TTS/speaker_encoder/__init__.py -> temp_build/TTS/speaker_encoder\n",
            "creating temp_build/TTS/vocoder\n",
            "copying TTS/vocoder/__init__.py -> temp_build/TTS/vocoder\n",
            "creating temp_build/TTS/tts\n",
            "copying TTS/tts/__init__.py -> temp_build/TTS/tts\n",
            "creating temp_build/TTS/server\n",
            "copying TTS/server/server.py -> temp_build/TTS/server\n",
            "copying TTS/server/__init__.py -> temp_build/TTS/server\n",
            "creating temp_build/TTS/bin\n",
            "copying TTS/bin/compute_embeddings.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/tune_wavegrad.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/distribute.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/resample.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/convert_melgan_tflite.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/train_tts.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/compute_statistics.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/train_encoder.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/convert_tacotron2_torch_to_tf.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/train_vocoder.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/find_unique_chars.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/extract_tts_spectrograms.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/synthesize.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/convert_melgan_torch_to_tf.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/convert_tacotron2_tflite.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/compute_attention_masks.py -> temp_build/TTS/bin\n",
            "copying TTS/bin/__init__.py -> temp_build/TTS/bin\n",
            "creating temp_build/TTS/utils\n",
            "copying TTS/utils/distribute.py -> temp_build/TTS/utils\n",
            "copying TTS/utils/callbacks.py -> temp_build/TTS/utils\n",
            "copying TTS/utils/training.py -> temp_build/TTS/utils\n",
            "copying TTS/utils/trainer_utils.py -> temp_build/TTS/utils\n",
            "copying TTS/utils/synthesizer.py -> temp_build/TTS/utils\n",
            "copying TTS/utils/radam.py -> temp_build/TTS/utils\n",
            "copying TTS/utils/manage.py -> temp_build/TTS/utils\n",
            "copying TTS/utils/audio.py -> temp_build/TTS/utils\n",
            "copying TTS/utils/io.py -> temp_build/TTS/utils\n",
            "copying TTS/utils/generic_utils.py -> temp_build/TTS/utils\n",
            "copying TTS/utils/__init__.py -> temp_build/TTS/utils\n",
            "creating temp_build/TTS/config\n",
            "copying TTS/config/shared_configs.py -> temp_build/TTS/config\n",
            "copying TTS/config/__init__.py -> temp_build/TTS/config\n",
            "creating temp_build/TTS/speaker_encoder/utils\n",
            "copying TTS/speaker_encoder/utils/prepare_voxceleb.py -> temp_build/TTS/speaker_encoder/utils\n",
            "copying TTS/speaker_encoder/utils/io.py -> temp_build/TTS/speaker_encoder/utils\n",
            "copying TTS/speaker_encoder/utils/generic_utils.py -> temp_build/TTS/speaker_encoder/utils\n",
            "copying TTS/speaker_encoder/utils/visual.py -> temp_build/TTS/speaker_encoder/utils\n",
            "copying TTS/speaker_encoder/utils/__init__.py -> temp_build/TTS/speaker_encoder/utils\n",
            "creating temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/parallel_wavegan_discriminator.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/wavernn.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/univnet_generator.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/melgan_generator.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/wavegrad.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/random_window_discriminator.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/melgan_multiscale_discriminator.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/hifigan_generator.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/gan.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/parallel_wavegan_generator.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/melgan_discriminator.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/fullband_melgan_generator.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/hifigan_discriminator.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/__init__.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/base_vocoder.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/univnet_discriminator.py -> temp_build/TTS/vocoder/models\n",
            "copying TTS/vocoder/models/multiband_melgan_generator.py -> temp_build/TTS/vocoder/models\n",
            "creating temp_build/TTS/vocoder/datasets\n",
            "copying TTS/vocoder/datasets/preprocess.py -> temp_build/TTS/vocoder/datasets\n",
            "copying TTS/vocoder/datasets/gan_dataset.py -> temp_build/TTS/vocoder/datasets\n",
            "copying TTS/vocoder/datasets/wavernn_dataset.py -> temp_build/TTS/vocoder/datasets\n",
            "copying TTS/vocoder/datasets/wavegrad_dataset.py -> temp_build/TTS/vocoder/datasets\n",
            "copying TTS/vocoder/datasets/__init__.py -> temp_build/TTS/vocoder/datasets\n",
            "creating temp_build/TTS/vocoder/layers\n",
            "copying TTS/vocoder/layers/lvc_block.py -> temp_build/TTS/vocoder/layers\n",
            "copying TTS/vocoder/layers/losses.py -> temp_build/TTS/vocoder/layers\n",
            "copying TTS/vocoder/layers/wavegrad.py -> temp_build/TTS/vocoder/layers\n",
            "copying TTS/vocoder/layers/parallel_wavegan.py -> temp_build/TTS/vocoder/layers\n",
            "copying TTS/vocoder/layers/hifigan.py -> temp_build/TTS/vocoder/layers\n",
            "copying TTS/vocoder/layers/pqmf.py -> temp_build/TTS/vocoder/layers\n",
            "copying TTS/vocoder/layers/upsample.py -> temp_build/TTS/vocoder/layers\n",
            "copying TTS/vocoder/layers/melgan.py -> temp_build/TTS/vocoder/layers\n",
            "copying TTS/vocoder/layers/__init__.py -> temp_build/TTS/vocoder/layers\n",
            "creating temp_build/TTS/vocoder/utils\n",
            "copying TTS/vocoder/utils/distribution.py -> temp_build/TTS/vocoder/utils\n",
            "copying TTS/vocoder/utils/generic_utils.py -> temp_build/TTS/vocoder/utils\n",
            "copying TTS/vocoder/utils/__init__.py -> temp_build/TTS/vocoder/utils\n",
            "creating temp_build/TTS/vocoder/configs\n",
            "copying TTS/vocoder/configs/multiband_melgan_config.py -> temp_build/TTS/vocoder/configs\n",
            "copying TTS/vocoder/configs/fullband_melgan_config.py -> temp_build/TTS/vocoder/configs\n",
            "copying TTS/vocoder/configs/univnet_config.py -> temp_build/TTS/vocoder/configs\n",
            "copying TTS/vocoder/configs/melgan_config.py -> temp_build/TTS/vocoder/configs\n",
            "copying TTS/vocoder/configs/parallel_wavegan_config.py -> temp_build/TTS/vocoder/configs\n",
            "copying TTS/vocoder/configs/wavegrad_config.py -> temp_build/TTS/vocoder/configs\n",
            "copying TTS/vocoder/configs/shared_configs.py -> temp_build/TTS/vocoder/configs\n",
            "copying TTS/vocoder/configs/wavernn_config.py -> temp_build/TTS/vocoder/configs\n",
            "copying TTS/vocoder/configs/hifigan_config.py -> temp_build/TTS/vocoder/configs\n",
            "copying TTS/vocoder/configs/__init__.py -> temp_build/TTS/vocoder/configs\n",
            "creating temp_build/TTS/tts/models\n",
            "copying TTS/tts/models/base_tts.py -> temp_build/TTS/tts/models\n",
            "copying TTS/tts/models/glow_tts.py -> temp_build/TTS/tts/models\n",
            "copying TTS/tts/models/tacotron2.py -> temp_build/TTS/tts/models\n",
            "copying TTS/tts/models/base_tacotron.py -> temp_build/TTS/tts/models\n",
            "copying TTS/tts/models/tacotron.py -> temp_build/TTS/tts/models\n",
            "copying TTS/tts/models/align_tts.py -> temp_build/TTS/tts/models\n",
            "copying TTS/tts/models/vits.py -> temp_build/TTS/tts/models\n",
            "copying TTS/tts/models/__init__.py -> temp_build/TTS/tts/models\n",
            "copying TTS/tts/models/speedy_speech.py -> temp_build/TTS/tts/models\n",
            "creating temp_build/TTS/tts/datasets\n",
            "copying TTS/tts/datasets/TTSDataset.py -> temp_build/TTS/tts/datasets\n",
            "copying TTS/tts/datasets/formatters.py -> temp_build/TTS/tts/datasets\n",
            "copying TTS/tts/datasets/__init__.py -> temp_build/TTS/tts/datasets\n",
            "creating temp_build/TTS/tts/layers\n",
            "copying TTS/tts/layers/losses.py -> temp_build/TTS/tts/layers\n",
            "copying TTS/tts/layers/__init__.py -> temp_build/TTS/tts/layers\n",
            "creating temp_build/TTS/tts/tf\n",
            "copying TTS/tts/tf/__init__.py -> temp_build/TTS/tts/tf\n",
            "creating temp_build/TTS/tts/utils\n",
            "copying TTS/tts/utils/speakers.py -> temp_build/TTS/tts/utils\n",
            "copying TTS/tts/utils/languages.py -> temp_build/TTS/tts/utils\n",
            "copying TTS/tts/utils/data.py -> temp_build/TTS/tts/utils\n",
            "copying TTS/tts/utils/ssim.py -> temp_build/TTS/tts/utils\n",
            "copying TTS/tts/utils/measures.py -> temp_build/TTS/tts/utils\n",
            "copying TTS/tts/utils/visual.py -> temp_build/TTS/tts/utils\n",
            "copying TTS/tts/utils/synthesis.py -> temp_build/TTS/tts/utils\n",
            "copying TTS/tts/utils/__init__.py -> temp_build/TTS/tts/utils\n",
            "creating temp_build/TTS/tts/configs\n",
            "copying TTS/tts/configs/speedy_speech_config.py -> temp_build/TTS/tts/configs\n",
            "copying TTS/tts/configs/align_tts_config.py -> temp_build/TTS/tts/configs\n",
            "copying TTS/tts/configs/tacotron_config.py -> temp_build/TTS/tts/configs\n",
            "copying TTS/tts/configs/shared_configs.py -> temp_build/TTS/tts/configs\n",
            "copying TTS/tts/configs/tacotron2_config.py -> temp_build/TTS/tts/configs\n",
            "copying TTS/tts/configs/vits_config.py -> temp_build/TTS/tts/configs\n",
            "copying TTS/tts/configs/glow_tts_config.py -> temp_build/TTS/tts/configs\n",
            "copying TTS/tts/configs/__init__.py -> temp_build/TTS/tts/configs\n",
            "creating temp_build/TTS/tts/layers/align_tts\n",
            "copying TTS/tts/layers/align_tts/mdn.py -> temp_build/TTS/tts/layers/align_tts\n",
            "copying TTS/tts/layers/align_tts/duration_predictor.py -> temp_build/TTS/tts/layers/align_tts\n",
            "copying TTS/tts/layers/align_tts/__init__.py -> temp_build/TTS/tts/layers/align_tts\n",
            "creating temp_build/TTS/tts/layers/generic\n",
            "copying TTS/tts/layers/generic/time_depth_sep_conv.py -> temp_build/TTS/tts/layers/generic\n",
            "copying TTS/tts/layers/generic/res_conv_bn.py -> temp_build/TTS/tts/layers/generic\n",
            "copying TTS/tts/layers/generic/gated_conv.py -> temp_build/TTS/tts/layers/generic\n",
            "copying TTS/tts/layers/generic/wavenet.py -> temp_build/TTS/tts/layers/generic\n",
            "copying TTS/tts/layers/generic/transformer.py -> temp_build/TTS/tts/layers/generic\n",
            "copying TTS/tts/layers/generic/pos_encoding.py -> temp_build/TTS/tts/layers/generic\n",
            "copying TTS/tts/layers/generic/__init__.py -> temp_build/TTS/tts/layers/generic\n",
            "copying TTS/tts/layers/generic/normalization.py -> temp_build/TTS/tts/layers/generic\n",
            "creating temp_build/TTS/tts/layers/tacotron\n",
            "copying TTS/tts/layers/tacotron/tacotron2.py -> temp_build/TTS/tts/layers/tacotron\n",
            "copying TTS/tts/layers/tacotron/common_layers.py -> temp_build/TTS/tts/layers/tacotron\n",
            "copying TTS/tts/layers/tacotron/attentions.py -> temp_build/TTS/tts/layers/tacotron\n",
            "copying TTS/tts/layers/tacotron/tacotron.py -> temp_build/TTS/tts/layers/tacotron\n",
            "copying TTS/tts/layers/tacotron/gst_layers.py -> temp_build/TTS/tts/layers/tacotron\n",
            "copying TTS/tts/layers/tacotron/__init__.py -> temp_build/TTS/tts/layers/tacotron\n",
            "creating temp_build/TTS/tts/layers/glow_tts\n",
            "copying TTS/tts/layers/glow_tts/decoder.py -> temp_build/TTS/tts/layers/glow_tts\n",
            "copying TTS/tts/layers/glow_tts/encoder.py -> temp_build/TTS/tts/layers/glow_tts\n",
            "copying TTS/tts/layers/glow_tts/glow.py -> temp_build/TTS/tts/layers/glow_tts\n",
            "copying TTS/tts/layers/glow_tts/transformer.py -> temp_build/TTS/tts/layers/glow_tts\n",
            "copying TTS/tts/layers/glow_tts/duration_predictor.py -> temp_build/TTS/tts/layers/glow_tts\n",
            "copying TTS/tts/layers/glow_tts/__init__.py -> temp_build/TTS/tts/layers/glow_tts\n",
            "creating temp_build/TTS/tts/layers/feed_forward\n",
            "copying TTS/tts/layers/feed_forward/decoder.py -> temp_build/TTS/tts/layers/feed_forward\n",
            "copying TTS/tts/layers/feed_forward/encoder.py -> temp_build/TTS/tts/layers/feed_forward\n",
            "copying TTS/tts/layers/feed_forward/duration_predictor.py -> temp_build/TTS/tts/layers/feed_forward\n",
            "copying TTS/tts/layers/feed_forward/__init__.py -> temp_build/TTS/tts/layers/feed_forward\n",
            "creating temp_build/TTS/tts/layers/glow_tts/monotonic_align\n",
            "copying TTS/tts/layers/glow_tts/monotonic_align/setup.py -> temp_build/TTS/tts/layers/glow_tts/monotonic_align\n",
            "copying TTS/tts/layers/glow_tts/monotonic_align/__init__.py -> temp_build/TTS/tts/layers/glow_tts/monotonic_align\n",
            "creating temp_build/TTS/tts/utils/text\n",
            "copying TTS/tts/utils/text/number_norm.py -> temp_build/TTS/tts/utils/text\n",
            "copying TTS/tts/utils/text/cleaners.py -> temp_build/TTS/tts/utils/text\n",
            "copying TTS/tts/utils/text/time.py -> temp_build/TTS/tts/utils/text\n",
            "copying TTS/tts/utils/text/abbreviations.py -> temp_build/TTS/tts/utils/text\n",
            "copying TTS/tts/utils/text/symbols.py -> temp_build/TTS/tts/utils/text\n",
            "copying TTS/tts/utils/text/cmudict.py -> temp_build/TTS/tts/utils/text\n",
            "copying TTS/tts/utils/text/__init__.py -> temp_build/TTS/tts/utils/text\n",
            "creating temp_build/TTS/tts/utils/text/japanese\n",
            "copying TTS/tts/utils/text/japanese/phonemizer.py -> temp_build/TTS/tts/utils/text/japanese\n",
            "copying TTS/tts/utils/text/japanese/__init__.py -> temp_build/TTS/tts/utils/text/japanese\n",
            "creating temp_build/TTS/tts/utils/text/chinese_mandarin\n",
            "copying TTS/tts/utils/text/chinese_mandarin/pinyinToPhonemes.py -> temp_build/TTS/tts/utils/text/chinese_mandarin\n",
            "copying TTS/tts/utils/text/chinese_mandarin/phonemizer.py -> temp_build/TTS/tts/utils/text/chinese_mandarin\n",
            "copying TTS/tts/utils/text/chinese_mandarin/numbers.py -> temp_build/TTS/tts/utils/text/chinese_mandarin\n",
            "copying TTS/tts/utils/text/chinese_mandarin/__init__.py -> temp_build/TTS/tts/utils/text/chinese_mandarin\n",
            "creating temp_build/TTS/utils/logging\n",
            "copying TTS/utils/logging/tensorboard_logger.py -> temp_build/TTS/utils/logging\n",
            "copying TTS/utils/logging/wandb_logger.py -> temp_build/TTS/utils/logging\n",
            "copying TTS/utils/logging/console_logger.py -> temp_build/TTS/utils/logging\n",
            "copying TTS/utils/logging/__init__.py -> temp_build/TTS/utils/logging\n",
            "copying TTS/.models.json -> temp_build/TTS\n",
            "copying TTS/VERSION -> temp_build/TTS\n",
            "copying TTS/speaker_encoder/README.md -> temp_build/TTS/speaker_encoder\n",
            "copying TTS/speaker_encoder/requirements.txt -> temp_build/TTS/speaker_encoder\n",
            "copying TTS/speaker_encoder/umap.png -> temp_build/TTS/speaker_encoder\n",
            "creating temp_build/TTS/speaker_encoder/configs\n",
            "copying TTS/speaker_encoder/configs/config.json -> temp_build/TTS/speaker_encoder/configs\n",
            "copying TTS/speaker_encoder/configs/config_resnet_angleproto.json -> temp_build/TTS/speaker_encoder/configs\n",
            "copying TTS/speaker_encoder/configs/config_resnet_softmax_angleproto.json -> temp_build/TTS/speaker_encoder/configs\n",
            "creating temp_build/TTS/speaker_encoder/models\n",
            "copying TTS/speaker_encoder/models/lstm.py -> temp_build/TTS/speaker_encoder/models\n",
            "copying TTS/speaker_encoder/models/resnet.py -> temp_build/TTS/speaker_encoder/models\n",
            "copying TTS/vocoder/README.md -> temp_build/TTS/vocoder\n",
            "copying TTS/vocoder/pqmf_output.wav -> temp_build/TTS/vocoder\n",
            "creating temp_build/TTS/vocoder/tf\n",
            "creating temp_build/TTS/vocoder/tf/layers\n",
            "copying TTS/vocoder/tf/layers/melgan.py -> temp_build/TTS/vocoder/tf/layers\n",
            "copying TTS/vocoder/tf/layers/pqmf.py -> temp_build/TTS/vocoder/tf/layers\n",
            "creating temp_build/TTS/vocoder/tf/models\n",
            "copying TTS/vocoder/tf/models/melgan_generator.py -> temp_build/TTS/vocoder/tf/models\n",
            "copying TTS/vocoder/tf/models/multiband_melgan_generator.py -> temp_build/TTS/vocoder/tf/models\n",
            "creating temp_build/TTS/vocoder/tf/utils\n",
            "copying TTS/vocoder/tf/utils/__init__.py -> temp_build/TTS/vocoder/tf/utils\n",
            "copying TTS/vocoder/tf/utils/convert_torch_to_tf_utils.py -> temp_build/TTS/vocoder/tf/utils\n",
            "copying TTS/vocoder/tf/utils/generic_utils.py -> temp_build/TTS/vocoder/tf/utils\n",
            "copying TTS/vocoder/tf/utils/io.py -> temp_build/TTS/vocoder/tf/utils\n",
            "copying TTS/vocoder/tf/utils/tflite.py -> temp_build/TTS/vocoder/tf/utils\n",
            "copying TTS/server/README.md -> temp_build/TTS/server\n",
            "copying TTS/server/conf.json -> temp_build/TTS/server\n",
            "creating temp_build/TTS/server/static\n",
            "copying TTS/server/static/coqui-log-green-TTS.png -> temp_build/TTS/server/static\n",
            "creating temp_build/TTS/server/templates\n",
            "copying TTS/server/templates/details.html -> temp_build/TTS/server/templates\n",
            "copying TTS/server/templates/index.html -> temp_build/TTS/server/templates\n",
            "copying TTS/vocoder/layers/qmf.dat -> temp_build/TTS/vocoder/layers\n",
            "creating temp_build/TTS/tts/layers/vits\n",
            "copying TTS/tts/layers/vits/discriminator.py -> temp_build/TTS/tts/layers/vits\n",
            "copying TTS/tts/layers/vits/networks.py -> temp_build/TTS/tts/layers/vits\n",
            "copying TTS/tts/layers/vits/stochastic_duration_predictor.py -> temp_build/TTS/tts/layers/vits\n",
            "copying TTS/tts/layers/vits/transforms.py -> temp_build/TTS/tts/layers/vits\n",
            "copying TTS/tts/tf/README.md -> temp_build/TTS/tts/tf\n",
            "creating temp_build/TTS/tts/tf/layers\n",
            "creating temp_build/TTS/tts/tf/layers/tacotron\n",
            "copying TTS/tts/tf/layers/tacotron/__init__.py -> temp_build/TTS/tts/tf/layers/tacotron\n",
            "copying TTS/tts/tf/layers/tacotron/common_layers.py -> temp_build/TTS/tts/tf/layers/tacotron\n",
            "copying TTS/tts/tf/layers/tacotron/tacotron2.py -> temp_build/TTS/tts/tf/layers/tacotron\n",
            "creating temp_build/TTS/tts/tf/models\n",
            "copying TTS/tts/tf/models/tacotron2.py -> temp_build/TTS/tts/tf/models\n",
            "creating temp_build/TTS/tts/tf/utils\n",
            "copying TTS/tts/tf/utils/convert_torch_to_tf_utils.py -> temp_build/TTS/tts/tf/utils\n",
            "copying TTS/tts/tf/utils/generic_utils.py -> temp_build/TTS/tts/tf/utils\n",
            "copying TTS/tts/tf/utils/io.py -> temp_build/TTS/tts/tf/utils\n",
            "copying TTS/tts/tf/utils/tf_utils.py -> temp_build/TTS/tts/tf/utils\n",
            "copying TTS/tts/tf/utils/tflite.py -> temp_build/TTS/tts/tf/utils\n",
            "copying TTS/tts/layers/glow_tts/monotonic_align/core.c -> temp_build/TTS/tts/layers/glow_tts/monotonic_align\n",
            "copying TTS/tts/layers/glow_tts/monotonic_align/core.pyx -> temp_build/TTS/tts/layers/glow_tts/monotonic_align\n",
            "running build_ext\n",
            "building 'TTS.tts.layers.glow_tts.monotonic_align.core' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/TTS\n",
            "creating build/temp.linux-x86_64-3.7/TTS/tts\n",
            "creating build/temp.linux-x86_64-3.7/TTS/tts/layers\n",
            "creating build/temp.linux-x86_64-3.7/TTS/tts/layers/glow_tts\n",
            "creating build/temp.linux-x86_64-3.7/TTS/tts/layers/glow_tts/monotonic_align\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c TTS/tts/layers/glow_tts/monotonic_align/core.c -o build/temp.linux-x86_64-3.7/TTS/tts/layers/glow_tts/monotonic_align/core.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1822:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[KTTS/tts/layers/glow_tts/monotonic_align/core.c:633\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/TTS\n",
            "creating build/lib.linux-x86_64-3.7/TTS/tts\n",
            "creating build/lib.linux-x86_64-3.7/TTS/tts/layers\n",
            "creating build/lib.linux-x86_64-3.7/TTS/tts/layers/glow_tts\n",
            "creating build/lib.linux-x86_64-3.7/TTS/tts/layers/glow_tts/monotonic_align\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/TTS/tts/layers/glow_tts/monotonic_align/core.o -o build/lib.linux-x86_64-3.7/TTS/tts/layers/glow_tts/monotonic_align/core.cpython-37m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/TTS\n",
            "copying temp_build/TTS/model.py -> build/bdist.linux-x86_64/egg/TTS\n",
            "creating build/bdist.linux-x86_64/egg/TTS/speaker_encoder\n",
            "creating build/bdist.linux-x86_64/egg/TTS/speaker_encoder/models\n",
            "copying temp_build/TTS/speaker_encoder/models/lstm.py -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder/models\n",
            "copying temp_build/TTS/speaker_encoder/models/resnet.py -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder/models\n",
            "copying temp_build/TTS/speaker_encoder/README.md -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder\n",
            "copying temp_build/TTS/speaker_encoder/losses.py -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder\n",
            "copying temp_build/TTS/speaker_encoder/umap.png -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder\n",
            "copying temp_build/TTS/speaker_encoder/speaker_encoder_config.py -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder\n",
            "copying temp_build/TTS/speaker_encoder/dataset.py -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder\n",
            "copying temp_build/TTS/speaker_encoder/requirements.txt -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder\n",
            "creating build/bdist.linux-x86_64/egg/TTS/speaker_encoder/utils\n",
            "copying temp_build/TTS/speaker_encoder/utils/prepare_voxceleb.py -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder/utils\n",
            "copying temp_build/TTS/speaker_encoder/utils/io.py -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder/utils\n",
            "copying temp_build/TTS/speaker_encoder/utils/generic_utils.py -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder/utils\n",
            "copying temp_build/TTS/speaker_encoder/utils/visual.py -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder/utils\n",
            "copying temp_build/TTS/speaker_encoder/utils/__init__.py -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder/utils\n",
            "creating build/bdist.linux-x86_64/egg/TTS/speaker_encoder/configs\n",
            "copying temp_build/TTS/speaker_encoder/configs/config_resnet_angleproto.json -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder/configs\n",
            "copying temp_build/TTS/speaker_encoder/configs/config.json -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder/configs\n",
            "copying temp_build/TTS/speaker_encoder/configs/config_resnet_softmax_angleproto.json -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder/configs\n",
            "copying temp_build/TTS/speaker_encoder/__init__.py -> build/bdist.linux-x86_64/egg/TTS/speaker_encoder\n",
            "creating build/bdist.linux-x86_64/egg/TTS/vocoder\n",
            "creating build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/parallel_wavegan_discriminator.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/wavernn.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/univnet_generator.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/melgan_generator.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/wavegrad.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/random_window_discriminator.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/melgan_multiscale_discriminator.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/hifigan_generator.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/gan.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/parallel_wavegan_generator.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/melgan_discriminator.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/fullband_melgan_generator.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/hifigan_discriminator.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/__init__.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/base_vocoder.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/univnet_discriminator.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "copying temp_build/TTS/vocoder/models/multiband_melgan_generator.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/models\n",
            "creating build/bdist.linux-x86_64/egg/TTS/vocoder/datasets\n",
            "copying temp_build/TTS/vocoder/datasets/preprocess.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/datasets\n",
            "copying temp_build/TTS/vocoder/datasets/gan_dataset.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/datasets\n",
            "copying temp_build/TTS/vocoder/datasets/wavernn_dataset.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/datasets\n",
            "copying temp_build/TTS/vocoder/datasets/wavegrad_dataset.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/datasets\n",
            "copying temp_build/TTS/vocoder/datasets/__init__.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/datasets\n",
            "copying temp_build/TTS/vocoder/README.md -> build/bdist.linux-x86_64/egg/TTS/vocoder\n",
            "creating build/bdist.linux-x86_64/egg/TTS/vocoder/layers\n",
            "copying temp_build/TTS/vocoder/layers/lvc_block.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/layers\n",
            "copying temp_build/TTS/vocoder/layers/losses.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/layers\n",
            "copying temp_build/TTS/vocoder/layers/wavegrad.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/layers\n",
            "copying temp_build/TTS/vocoder/layers/parallel_wavegan.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/layers\n",
            "copying temp_build/TTS/vocoder/layers/hifigan.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/layers\n",
            "copying temp_build/TTS/vocoder/layers/pqmf.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/layers\n",
            "copying temp_build/TTS/vocoder/layers/qmf.dat -> build/bdist.linux-x86_64/egg/TTS/vocoder/layers\n",
            "copying temp_build/TTS/vocoder/layers/upsample.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/layers\n",
            "copying temp_build/TTS/vocoder/layers/melgan.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/layers\n",
            "copying temp_build/TTS/vocoder/layers/__init__.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/layers\n",
            "creating build/bdist.linux-x86_64/egg/TTS/vocoder/tf\n",
            "creating build/bdist.linux-x86_64/egg/TTS/vocoder/tf/models\n",
            "copying temp_build/TTS/vocoder/tf/models/melgan_generator.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/tf/models\n",
            "copying temp_build/TTS/vocoder/tf/models/multiband_melgan_generator.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/tf/models\n",
            "creating build/bdist.linux-x86_64/egg/TTS/vocoder/tf/layers\n",
            "copying temp_build/TTS/vocoder/tf/layers/pqmf.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/tf/layers\n",
            "copying temp_build/TTS/vocoder/tf/layers/melgan.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/tf/layers\n",
            "creating build/bdist.linux-x86_64/egg/TTS/vocoder/tf/utils\n",
            "copying temp_build/TTS/vocoder/tf/utils/tflite.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/tf/utils\n",
            "copying temp_build/TTS/vocoder/tf/utils/io.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/tf/utils\n",
            "copying temp_build/TTS/vocoder/tf/utils/convert_torch_to_tf_utils.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/tf/utils\n",
            "copying temp_build/TTS/vocoder/tf/utils/generic_utils.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/tf/utils\n",
            "copying temp_build/TTS/vocoder/tf/utils/__init__.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/tf/utils\n",
            "copying temp_build/TTS/vocoder/pqmf_output.wav -> build/bdist.linux-x86_64/egg/TTS/vocoder\n",
            "creating build/bdist.linux-x86_64/egg/TTS/vocoder/utils\n",
            "copying temp_build/TTS/vocoder/utils/distribution.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/utils\n",
            "copying temp_build/TTS/vocoder/utils/generic_utils.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/utils\n",
            "copying temp_build/TTS/vocoder/utils/__init__.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/utils\n",
            "creating build/bdist.linux-x86_64/egg/TTS/vocoder/configs\n",
            "copying temp_build/TTS/vocoder/configs/multiband_melgan_config.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/configs\n",
            "copying temp_build/TTS/vocoder/configs/fullband_melgan_config.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/configs\n",
            "copying temp_build/TTS/vocoder/configs/univnet_config.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/configs\n",
            "copying temp_build/TTS/vocoder/configs/melgan_config.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/configs\n",
            "copying temp_build/TTS/vocoder/configs/parallel_wavegan_config.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/configs\n",
            "copying temp_build/TTS/vocoder/configs/wavegrad_config.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/configs\n",
            "copying temp_build/TTS/vocoder/configs/shared_configs.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/configs\n",
            "copying temp_build/TTS/vocoder/configs/wavernn_config.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/configs\n",
            "copying temp_build/TTS/vocoder/configs/hifigan_config.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/configs\n",
            "copying temp_build/TTS/vocoder/configs/__init__.py -> build/bdist.linux-x86_64/egg/TTS/vocoder/configs\n",
            "copying temp_build/TTS/vocoder/__init__.py -> build/bdist.linux-x86_64/egg/TTS/vocoder\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/models\n",
            "copying temp_build/TTS/tts/models/base_tts.py -> build/bdist.linux-x86_64/egg/TTS/tts/models\n",
            "copying temp_build/TTS/tts/models/glow_tts.py -> build/bdist.linux-x86_64/egg/TTS/tts/models\n",
            "copying temp_build/TTS/tts/models/tacotron2.py -> build/bdist.linux-x86_64/egg/TTS/tts/models\n",
            "copying temp_build/TTS/tts/models/base_tacotron.py -> build/bdist.linux-x86_64/egg/TTS/tts/models\n",
            "copying temp_build/TTS/tts/models/tacotron.py -> build/bdist.linux-x86_64/egg/TTS/tts/models\n",
            "copying temp_build/TTS/tts/models/align_tts.py -> build/bdist.linux-x86_64/egg/TTS/tts/models\n",
            "copying temp_build/TTS/tts/models/vits.py -> build/bdist.linux-x86_64/egg/TTS/tts/models\n",
            "copying temp_build/TTS/tts/models/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/models\n",
            "copying temp_build/TTS/tts/models/speedy_speech.py -> build/bdist.linux-x86_64/egg/TTS/tts/models\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/datasets\n",
            "copying temp_build/TTS/tts/datasets/TTSDataset.py -> build/bdist.linux-x86_64/egg/TTS/tts/datasets\n",
            "copying temp_build/TTS/tts/datasets/formatters.py -> build/bdist.linux-x86_64/egg/TTS/tts/datasets\n",
            "copying temp_build/TTS/tts/datasets/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/datasets\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/layers\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/layers/align_tts\n",
            "copying temp_build/TTS/tts/layers/align_tts/mdn.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/align_tts\n",
            "copying temp_build/TTS/tts/layers/align_tts/duration_predictor.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/align_tts\n",
            "copying temp_build/TTS/tts/layers/align_tts/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/align_tts\n",
            "copying temp_build/TTS/tts/layers/losses.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/layers/generic\n",
            "copying temp_build/TTS/tts/layers/generic/time_depth_sep_conv.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/generic\n",
            "copying temp_build/TTS/tts/layers/generic/res_conv_bn.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/generic\n",
            "copying temp_build/TTS/tts/layers/generic/gated_conv.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/generic\n",
            "copying temp_build/TTS/tts/layers/generic/wavenet.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/generic\n",
            "copying temp_build/TTS/tts/layers/generic/transformer.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/generic\n",
            "copying temp_build/TTS/tts/layers/generic/pos_encoding.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/generic\n",
            "copying temp_build/TTS/tts/layers/generic/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/generic\n",
            "copying temp_build/TTS/tts/layers/generic/normalization.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/generic\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/layers/tacotron\n",
            "copying temp_build/TTS/tts/layers/tacotron/tacotron2.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/tacotron\n",
            "copying temp_build/TTS/tts/layers/tacotron/common_layers.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/tacotron\n",
            "copying temp_build/TTS/tts/layers/tacotron/attentions.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/tacotron\n",
            "copying temp_build/TTS/tts/layers/tacotron/tacotron.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/tacotron\n",
            "copying temp_build/TTS/tts/layers/tacotron/gst_layers.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/tacotron\n",
            "copying temp_build/TTS/tts/layers/tacotron/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/tacotron\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts\n",
            "copying temp_build/TTS/tts/layers/glow_tts/decoder.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts\n",
            "copying temp_build/TTS/tts/layers/glow_tts/encoder.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts\n",
            "copying temp_build/TTS/tts/layers/glow_tts/glow.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts\n",
            "copying temp_build/TTS/tts/layers/glow_tts/transformer.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts\n",
            "copying temp_build/TTS/tts/layers/glow_tts/duration_predictor.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts/monotonic_align\n",
            "copying temp_build/TTS/tts/layers/glow_tts/monotonic_align/setup.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts/monotonic_align\n",
            "copying temp_build/TTS/tts/layers/glow_tts/monotonic_align/core.c -> build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts/monotonic_align\n",
            "copying temp_build/TTS/tts/layers/glow_tts/monotonic_align/core.pyx -> build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts/monotonic_align\n",
            "copying temp_build/TTS/tts/layers/glow_tts/monotonic_align/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts/monotonic_align\n",
            "copying temp_build/TTS/tts/layers/glow_tts/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/layers/vits\n",
            "copying temp_build/TTS/tts/layers/vits/discriminator.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/vits\n",
            "copying temp_build/TTS/tts/layers/vits/transforms.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/vits\n",
            "copying temp_build/TTS/tts/layers/vits/networks.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/vits\n",
            "copying temp_build/TTS/tts/layers/vits/stochastic_duration_predictor.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/vits\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/layers/feed_forward\n",
            "copying temp_build/TTS/tts/layers/feed_forward/decoder.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/feed_forward\n",
            "copying temp_build/TTS/tts/layers/feed_forward/encoder.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/feed_forward\n",
            "copying temp_build/TTS/tts/layers/feed_forward/duration_predictor.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/feed_forward\n",
            "copying temp_build/TTS/tts/layers/feed_forward/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers/feed_forward\n",
            "copying temp_build/TTS/tts/layers/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/layers\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/tf\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/tf/models\n",
            "copying temp_build/TTS/tts/tf/models/tacotron2.py -> build/bdist.linux-x86_64/egg/TTS/tts/tf/models\n",
            "copying temp_build/TTS/tts/tf/README.md -> build/bdist.linux-x86_64/egg/TTS/tts/tf\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/tf/layers\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/tf/layers/tacotron\n",
            "copying temp_build/TTS/tts/tf/layers/tacotron/tacotron2.py -> build/bdist.linux-x86_64/egg/TTS/tts/tf/layers/tacotron\n",
            "copying temp_build/TTS/tts/tf/layers/tacotron/common_layers.py -> build/bdist.linux-x86_64/egg/TTS/tts/tf/layers/tacotron\n",
            "copying temp_build/TTS/tts/tf/layers/tacotron/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/tf/layers/tacotron\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/tf/utils\n",
            "copying temp_build/TTS/tts/tf/utils/tf_utils.py -> build/bdist.linux-x86_64/egg/TTS/tts/tf/utils\n",
            "copying temp_build/TTS/tts/tf/utils/tflite.py -> build/bdist.linux-x86_64/egg/TTS/tts/tf/utils\n",
            "copying temp_build/TTS/tts/tf/utils/io.py -> build/bdist.linux-x86_64/egg/TTS/tts/tf/utils\n",
            "copying temp_build/TTS/tts/tf/utils/convert_torch_to_tf_utils.py -> build/bdist.linux-x86_64/egg/TTS/tts/tf/utils\n",
            "copying temp_build/TTS/tts/tf/utils/generic_utils.py -> build/bdist.linux-x86_64/egg/TTS/tts/tf/utils\n",
            "copying temp_build/TTS/tts/tf/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/tf\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/utils\n",
            "copying temp_build/TTS/tts/utils/speakers.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils\n",
            "copying temp_build/TTS/tts/utils/languages.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/utils/text\n",
            "copying temp_build/TTS/tts/utils/text/number_norm.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils/text\n",
            "copying temp_build/TTS/tts/utils/text/cleaners.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils/text\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/utils/text/japanese\n",
            "copying temp_build/TTS/tts/utils/text/japanese/phonemizer.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils/text/japanese\n",
            "copying temp_build/TTS/tts/utils/text/japanese/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils/text/japanese\n",
            "copying temp_build/TTS/tts/utils/text/time.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils/text\n",
            "copying temp_build/TTS/tts/utils/text/abbreviations.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils/text\n",
            "copying temp_build/TTS/tts/utils/text/symbols.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils/text\n",
            "copying temp_build/TTS/tts/utils/text/cmudict.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils/text\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/utils/text/chinese_mandarin\n",
            "copying temp_build/TTS/tts/utils/text/chinese_mandarin/pinyinToPhonemes.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils/text/chinese_mandarin\n",
            "copying temp_build/TTS/tts/utils/text/chinese_mandarin/phonemizer.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils/text/chinese_mandarin\n",
            "copying temp_build/TTS/tts/utils/text/chinese_mandarin/numbers.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils/text/chinese_mandarin\n",
            "copying temp_build/TTS/tts/utils/text/chinese_mandarin/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils/text/chinese_mandarin\n",
            "copying temp_build/TTS/tts/utils/text/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils/text\n",
            "copying temp_build/TTS/tts/utils/data.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils\n",
            "copying temp_build/TTS/tts/utils/ssim.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils\n",
            "copying temp_build/TTS/tts/utils/measures.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils\n",
            "copying temp_build/TTS/tts/utils/visual.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils\n",
            "copying temp_build/TTS/tts/utils/synthesis.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils\n",
            "copying temp_build/TTS/tts/utils/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/utils\n",
            "creating build/bdist.linux-x86_64/egg/TTS/tts/configs\n",
            "copying temp_build/TTS/tts/configs/speedy_speech_config.py -> build/bdist.linux-x86_64/egg/TTS/tts/configs\n",
            "copying temp_build/TTS/tts/configs/align_tts_config.py -> build/bdist.linux-x86_64/egg/TTS/tts/configs\n",
            "copying temp_build/TTS/tts/configs/tacotron_config.py -> build/bdist.linux-x86_64/egg/TTS/tts/configs\n",
            "copying temp_build/TTS/tts/configs/shared_configs.py -> build/bdist.linux-x86_64/egg/TTS/tts/configs\n",
            "copying temp_build/TTS/tts/configs/tacotron2_config.py -> build/bdist.linux-x86_64/egg/TTS/tts/configs\n",
            "copying temp_build/TTS/tts/configs/vits_config.py -> build/bdist.linux-x86_64/egg/TTS/tts/configs\n",
            "copying temp_build/TTS/tts/configs/glow_tts_config.py -> build/bdist.linux-x86_64/egg/TTS/tts/configs\n",
            "copying temp_build/TTS/tts/configs/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts/configs\n",
            "copying temp_build/TTS/tts/__init__.py -> build/bdist.linux-x86_64/egg/TTS/tts\n",
            "copying temp_build/TTS/trainer.py -> build/bdist.linux-x86_64/egg/TTS\n",
            "creating build/bdist.linux-x86_64/egg/TTS/server\n",
            "copying temp_build/TTS/server/server.py -> build/bdist.linux-x86_64/egg/TTS/server\n",
            "copying temp_build/TTS/server/README.md -> build/bdist.linux-x86_64/egg/TTS/server\n",
            "creating build/bdist.linux-x86_64/egg/TTS/server/templates\n",
            "copying temp_build/TTS/server/templates/index.html -> build/bdist.linux-x86_64/egg/TTS/server/templates\n",
            "copying temp_build/TTS/server/templates/details.html -> build/bdist.linux-x86_64/egg/TTS/server/templates\n",
            "copying temp_build/TTS/server/conf.json -> build/bdist.linux-x86_64/egg/TTS/server\n",
            "creating build/bdist.linux-x86_64/egg/TTS/server/static\n",
            "copying temp_build/TTS/server/static/coqui-log-green-TTS.png -> build/bdist.linux-x86_64/egg/TTS/server/static\n",
            "copying temp_build/TTS/server/__init__.py -> build/bdist.linux-x86_64/egg/TTS/server\n",
            "creating build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/compute_embeddings.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/tune_wavegrad.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/distribute.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/resample.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/convert_melgan_tflite.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/train_tts.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/compute_statistics.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/train_encoder.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/convert_tacotron2_torch_to_tf.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/train_vocoder.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/find_unique_chars.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/extract_tts_spectrograms.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/synthesize.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/convert_melgan_torch_to_tf.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/convert_tacotron2_tflite.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/compute_attention_masks.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/bin/__init__.py -> build/bdist.linux-x86_64/egg/TTS/bin\n",
            "copying temp_build/TTS/VERSION -> build/bdist.linux-x86_64/egg/TTS\n",
            "creating build/bdist.linux-x86_64/egg/TTS/utils\n",
            "copying temp_build/TTS/utils/distribute.py -> build/bdist.linux-x86_64/egg/TTS/utils\n",
            "creating build/bdist.linux-x86_64/egg/TTS/utils/logging\n",
            "copying temp_build/TTS/utils/logging/tensorboard_logger.py -> build/bdist.linux-x86_64/egg/TTS/utils/logging\n",
            "copying temp_build/TTS/utils/logging/wandb_logger.py -> build/bdist.linux-x86_64/egg/TTS/utils/logging\n",
            "copying temp_build/TTS/utils/logging/console_logger.py -> build/bdist.linux-x86_64/egg/TTS/utils/logging\n",
            "copying temp_build/TTS/utils/logging/__init__.py -> build/bdist.linux-x86_64/egg/TTS/utils/logging\n",
            "copying temp_build/TTS/utils/callbacks.py -> build/bdist.linux-x86_64/egg/TTS/utils\n",
            "copying temp_build/TTS/utils/training.py -> build/bdist.linux-x86_64/egg/TTS/utils\n",
            "copying temp_build/TTS/utils/trainer_utils.py -> build/bdist.linux-x86_64/egg/TTS/utils\n",
            "copying temp_build/TTS/utils/synthesizer.py -> build/bdist.linux-x86_64/egg/TTS/utils\n",
            "copying temp_build/TTS/utils/radam.py -> build/bdist.linux-x86_64/egg/TTS/utils\n",
            "copying temp_build/TTS/utils/manage.py -> build/bdist.linux-x86_64/egg/TTS/utils\n",
            "copying temp_build/TTS/utils/audio.py -> build/bdist.linux-x86_64/egg/TTS/utils\n",
            "copying temp_build/TTS/utils/io.py -> build/bdist.linux-x86_64/egg/TTS/utils\n",
            "copying temp_build/TTS/utils/generic_utils.py -> build/bdist.linux-x86_64/egg/TTS/utils\n",
            "copying temp_build/TTS/utils/__init__.py -> build/bdist.linux-x86_64/egg/TTS/utils\n",
            "creating build/bdist.linux-x86_64/egg/TTS/config\n",
            "copying temp_build/TTS/config/shared_configs.py -> build/bdist.linux-x86_64/egg/TTS/config\n",
            "copying temp_build/TTS/config/__init__.py -> build/bdist.linux-x86_64/egg/TTS/config\n",
            "copying temp_build/TTS/.models.json -> build/bdist.linux-x86_64/egg/TTS\n",
            "copying temp_build/TTS/__init__.py -> build/bdist.linux-x86_64/egg/TTS\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/model.py to model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/speaker_encoder/models/lstm.py to lstm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/speaker_encoder/models/resnet.py to resnet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/speaker_encoder/losses.py to losses.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/speaker_encoder/speaker_encoder_config.py to speaker_encoder_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/speaker_encoder/dataset.py to dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/speaker_encoder/utils/prepare_voxceleb.py to prepare_voxceleb.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/speaker_encoder/utils/io.py to io.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/speaker_encoder/utils/generic_utils.py to generic_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/speaker_encoder/utils/visual.py to visual.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/speaker_encoder/utils/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/speaker_encoder/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/parallel_wavegan_discriminator.py to parallel_wavegan_discriminator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/wavernn.py to wavernn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/univnet_generator.py to univnet_generator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/melgan_generator.py to melgan_generator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/wavegrad.py to wavegrad.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/random_window_discriminator.py to random_window_discriminator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/melgan_multiscale_discriminator.py to melgan_multiscale_discriminator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/hifigan_generator.py to hifigan_generator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/gan.py to gan.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/parallel_wavegan_generator.py to parallel_wavegan_generator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/melgan_discriminator.py to melgan_discriminator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/fullband_melgan_generator.py to fullband_melgan_generator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/hifigan_discriminator.py to hifigan_discriminator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/base_vocoder.py to base_vocoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/univnet_discriminator.py to univnet_discriminator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/models/multiband_melgan_generator.py to multiband_melgan_generator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/datasets/preprocess.py to preprocess.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/datasets/gan_dataset.py to gan_dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/datasets/wavernn_dataset.py to wavernn_dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/datasets/wavegrad_dataset.py to wavegrad_dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/datasets/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/layers/lvc_block.py to lvc_block.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/layers/losses.py to losses.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/layers/wavegrad.py to wavegrad.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/layers/parallel_wavegan.py to parallel_wavegan.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/layers/hifigan.py to hifigan.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/layers/pqmf.py to pqmf.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/layers/upsample.py to upsample.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/layers/melgan.py to melgan.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/layers/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/tf/models/melgan_generator.py to melgan_generator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/tf/models/multiband_melgan_generator.py to multiband_melgan_generator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/tf/layers/pqmf.py to pqmf.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/tf/layers/melgan.py to melgan.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/tf/utils/tflite.py to tflite.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/tf/utils/io.py to io.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/tf/utils/convert_torch_to_tf_utils.py to convert_torch_to_tf_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/tf/utils/generic_utils.py to generic_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/tf/utils/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/utils/distribution.py to distribution.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/utils/generic_utils.py to generic_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/utils/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/configs/multiband_melgan_config.py to multiband_melgan_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/configs/fullband_melgan_config.py to fullband_melgan_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/configs/univnet_config.py to univnet_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/configs/melgan_config.py to melgan_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/configs/parallel_wavegan_config.py to parallel_wavegan_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/configs/wavegrad_config.py to wavegrad_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/configs/shared_configs.py to shared_configs.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/configs/wavernn_config.py to wavernn_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/configs/hifigan_config.py to hifigan_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/configs/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/vocoder/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/models/base_tts.py to base_tts.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/models/glow_tts.py to glow_tts.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/models/tacotron2.py to tacotron2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/models/base_tacotron.py to base_tacotron.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/models/tacotron.py to tacotron.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/models/align_tts.py to align_tts.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/models/vits.py to vits.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/models/speedy_speech.py to speedy_speech.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/datasets/TTSDataset.py to TTSDataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/datasets/formatters.py to formatters.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/datasets/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/align_tts/mdn.py to mdn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/align_tts/duration_predictor.py to duration_predictor.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/align_tts/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/losses.py to losses.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/generic/time_depth_sep_conv.py to time_depth_sep_conv.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/generic/res_conv_bn.py to res_conv_bn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/generic/gated_conv.py to gated_conv.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/generic/wavenet.py to wavenet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/generic/transformer.py to transformer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/generic/pos_encoding.py to pos_encoding.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/generic/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/generic/normalization.py to normalization.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/tacotron/tacotron2.py to tacotron2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/tacotron/common_layers.py to common_layers.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/tacotron/attentions.py to attentions.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/tacotron/tacotron.py to tacotron.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/tacotron/gst_layers.py to gst_layers.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/tacotron/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts/decoder.py to decoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts/encoder.py to encoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts/glow.py to glow.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts/transformer.py to transformer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts/duration_predictor.py to duration_predictor.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts/monotonic_align/setup.py to setup.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts/monotonic_align/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/glow_tts/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/vits/discriminator.py to discriminator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/vits/transforms.py to transforms.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/vits/networks.py to networks.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/vits/stochastic_duration_predictor.py to stochastic_duration_predictor.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/feed_forward/decoder.py to decoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/feed_forward/encoder.py to encoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/feed_forward/duration_predictor.py to duration_predictor.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/feed_forward/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/layers/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/tf/models/tacotron2.py to tacotron2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/tf/layers/tacotron/tacotron2.py to tacotron2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/tf/layers/tacotron/common_layers.py to common_layers.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/tf/layers/tacotron/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/tf/utils/tf_utils.py to tf_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/tf/utils/tflite.py to tflite.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/tf/utils/io.py to io.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/tf/utils/convert_torch_to_tf_utils.py to convert_torch_to_tf_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/tf/utils/generic_utils.py to generic_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/tf/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/speakers.py to speakers.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/languages.py to languages.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/text/number_norm.py to number_norm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/text/cleaners.py to cleaners.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/text/japanese/phonemizer.py to phonemizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/text/japanese/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/text/time.py to time.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/text/abbreviations.py to abbreviations.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/text/symbols.py to symbols.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/text/cmudict.py to cmudict.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/text/chinese_mandarin/pinyinToPhonemes.py to pinyinToPhonemes.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/text/chinese_mandarin/phonemizer.py to phonemizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/text/chinese_mandarin/numbers.py to numbers.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/text/chinese_mandarin/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/text/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/data.py to data.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/ssim.py to ssim.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/measures.py to measures.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/visual.py to visual.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/synthesis.py to synthesis.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/utils/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/configs/speedy_speech_config.py to speedy_speech_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/configs/align_tts_config.py to align_tts_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/configs/tacotron_config.py to tacotron_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/configs/shared_configs.py to shared_configs.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/configs/tacotron2_config.py to tacotron2_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/configs/vits_config.py to vits_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/configs/glow_tts_config.py to glow_tts_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/configs/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/tts/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/trainer.py to trainer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/server/server.py to server.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/server/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/compute_embeddings.py to compute_embeddings.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/tune_wavegrad.py to tune_wavegrad.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/distribute.py to distribute.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/resample.py to resample.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/convert_melgan_tflite.py to convert_melgan_tflite.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/train_tts.py to train_tts.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/compute_statistics.py to compute_statistics.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/train_encoder.py to train_encoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/convert_tacotron2_torch_to_tf.py to convert_tacotron2_torch_to_tf.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/train_vocoder.py to train_vocoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/find_unique_chars.py to find_unique_chars.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/extract_tts_spectrograms.py to extract_tts_spectrograms.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/synthesize.py to synthesize.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/convert_melgan_torch_to_tf.py to convert_melgan_torch_to_tf.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/convert_tacotron2_tflite.py to convert_tacotron2_tflite.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/compute_attention_masks.py to compute_attention_masks.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/bin/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/utils/distribute.py to distribute.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/utils/logging/tensorboard_logger.py to tensorboard_logger.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/utils/logging/wandb_logger.py to wandb_logger.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/utils/logging/console_logger.py to console_logger.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/utils/logging/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/utils/callbacks.py to callbacks.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/utils/training.py to training.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/utils/trainer_utils.py to trainer_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/utils/synthesizer.py to synthesizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/utils/radam.py to radam.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/utils/manage.py to manage.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/utils/audio.py to audio.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/utils/io.py to io.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/utils/generic_utils.py to generic_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/utils/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/config/shared_configs.py to shared_configs.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/config/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/TTS/__init__.py to __init__.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TTS.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TTS.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TTS.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TTS.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TTS.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TTS.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TTS.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "creating dist\n",
            "creating 'dist/TTS-0.2.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing TTS-0.2.0-py3.7-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/TTS-0.2.0-py3.7-linux-x86_64.egg\n",
            "Extracting TTS-0.2.0-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding TTS 0.2.0 to easy-install.pth file\n",
            "Installing tts script to /usr/local/bin\n",
            "Installing tts-server script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/TTS-0.2.0-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for TTS==0.2.0\n",
            "Searching for fsspec==2021.10.0\n",
            "Best match: fsspec 2021.10.0\n",
            "Adding fsspec 2021.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut==1.2.3\n",
            "Best match: gruut 1.2.3\n",
            "Adding gruut 1.2.3 to easy-install.pth file\n",
            "Installing gruut script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for unidic-lite==1.0.8\n",
            "Best match: unidic-lite 1.0.8\n",
            "Adding unidic-lite 1.0.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for mecab-python3==1.0.3\n",
            "Best match: mecab-python3 1.0.3\n",
            "Adding mecab-python3 1.0.3 to easy-install.pth file\n",
            "Installing mecab-py script to /usr/local/bin\n",
            "Installing mecab-py-info script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for coqpit==0.0.14\n",
            "Best match: coqpit 0.0.14\n",
            "Adding coqpit 0.0.14 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for anyascii==0.3.0\n",
            "Best match: anyascii 0.3.0\n",
            "Adding anyascii 0.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for umap-learn==0.5.1\n",
            "Best match: umap-learn 0.5.1\n",
            "Adding umap-learn 0.5.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numba==0.53.0\n",
            "Best match: numba 0.53.0\n",
            "Adding numba 0.53.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.62.3\n",
            "Best match: tqdm 4.62.3\n",
            "Adding tqdm 4.62.3 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torch==1.9.0+cu102\n",
            "Best match: torch 1.9.0+cu102\n",
            "Adding torch 1.9.0+cu102 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboardX==2.4\n",
            "Best match: tensorboardX 2.4\n",
            "Adding tensorboardX 2.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for SoundFile==0.10.3.post1\n",
            "Best match: SoundFile 0.10.3.post1\n",
            "Adding SoundFile 0.10.3.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for PyYAML==3.13\n",
            "Best match: PyYAML 3.13\n",
            "Adding PyYAML 3.13 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pysbd==0.3.4\n",
            "Best match: pysbd 0.3.4\n",
            "Adding pysbd 0.3.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pypinyin==0.42.1\n",
            "Best match: pypinyin 0.42.1\n",
            "Adding pypinyin 0.42.1 to easy-install.pth file\n",
            "Installing pypinyin script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pandas==1.1.5\n",
            "Best match: pandas 1.1.5\n",
            "Adding pandas 1.1.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for matplotlib==3.2.2\n",
            "Best match: matplotlib 3.2.2\n",
            "Adding matplotlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for librosa==0.8.0\n",
            "Best match: librosa 0.8.0\n",
            "Adding librosa 0.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for jieba==0.42.1\n",
            "Best match: jieba 0.42.1\n",
            "Adding jieba 0.42.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for inflect==2.1.0\n",
            "Best match: inflect 2.1.0\n",
            "Adding inflect 2.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gdown==3.6.4\n",
            "Best match: gdown 3.6.4\n",
            "Adding gdown 3.6.4 to easy-install.pth file\n",
            "Installing gdown script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Flask==1.1.4\n",
            "Best match: Flask 1.1.4\n",
            "Adding Flask 1.1.4 to easy-install.pth file\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Cython==0.29.24\n",
            "Best match: Cython 0.29.24\n",
            "Adding Cython 0.29.24 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-cs==1.2\n",
            "Best match: gruut-lang-cs 1.2\n",
            "Adding gruut-lang-cs 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-es==1.2\n",
            "Best match: gruut-lang-es 1.2\n",
            "Adding gruut-lang-es 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-nl==1.2\n",
            "Best match: gruut-lang-nl 1.2\n",
            "Adding gruut-lang-nl 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-ru==1.2\n",
            "Best match: gruut-lang-ru 1.2\n",
            "Adding gruut-lang-ru 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-pt==1.2\n",
            "Best match: gruut-lang-pt 1.2\n",
            "Adding gruut-lang-pt 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-it==1.2\n",
            "Best match: gruut-lang-it 1.2\n",
            "Adding gruut-lang-it 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-fr==1.2.1\n",
            "Best match: gruut-lang-fr 1.2.1\n",
            "Adding gruut-lang-fr 1.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-de==1.2\n",
            "Best match: gruut-lang-de 1.2\n",
            "Adding gruut-lang-de 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-sv==1.2\n",
            "Best match: gruut-lang-sv 1.2\n",
            "Adding gruut-lang-sv 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for num2words==0.5.10\n",
            "Best match: num2words 0.5.10\n",
            "Adding num2words 0.5.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for jsonlines==1.2.0\n",
            "Best match: jsonlines 1.2.0\n",
            "Adding jsonlines 1.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-ipa==0.9.3\n",
            "Best match: gruut-ipa 0.9.3\n",
            "Adding gruut-ipa 0.9.3 to easy-install.pth file\n",
            "Installing gruut-ipa script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-crfsuite==0.9.7\n",
            "Best match: python-crfsuite 0.9.7\n",
            "Adding python-crfsuite 0.9.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Babel==2.8.1\n",
            "Best match: Babel 2.8.1\n",
            "Adding Babel 2.8.1 to easy-install.pth file\n",
            "Installing pybabel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scikit-learn==0.22.2.post1\n",
            "Best match: scikit-learn 0.22.2.post1\n",
            "Adding scikit-learn 0.22.2.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pynndescent==0.5.4\n",
            "Best match: pynndescent 0.5.4\n",
            "Adding pynndescent 0.5.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for setuptools==57.4.0\n",
            "Best match: setuptools 57.4.0\n",
            "Adding setuptools 57.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for llvmlite==0.36.0\n",
            "Best match: llvmlite 0.36.0\n",
            "Adding llvmlite 0.36.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==3.7.4.3\n",
            "Best match: typing-extensions 3.7.4.3\n",
            "Adding typing-extensions 3.7.4.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for protobuf==3.17.3\n",
            "Best match: protobuf 3.17.3\n",
            "Adding protobuf 3.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cffi==1.14.6\n",
            "Best match: cffi 1.14.6\n",
            "Adding cffi 1.14.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pytz==2018.9\n",
            "Best match: pytz 2018.9\n",
            "Adding pytz 2018.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cycler==0.10.0\n",
            "Best match: cycler 0.10.0\n",
            "Adding cycler 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyparsing==2.4.7\n",
            "Best match: pyparsing 2.4.7\n",
            "Adding pyparsing 2.4.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for kiwisolver==1.3.2\n",
            "Best match: kiwisolver 1.3.2\n",
            "Adding kiwisolver 1.3.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for resampy==0.2.2\n",
            "Best match: resampy 0.2.2\n",
            "Adding resampy 0.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for joblib==1.0.1\n",
            "Best match: joblib 1.0.1\n",
            "Adding joblib 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for audioread==2.1.9\n",
            "Best match: audioread 2.1.9\n",
            "Adding audioread 2.1.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pooch==1.5.1\n",
            "Best match: pooch 1.5.1\n",
            "Adding pooch 1.5.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for decorator==4.4.2\n",
            "Best match: decorator 4.4.2\n",
            "Adding decorator 4.4.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for click==7.1.2\n",
            "Best match: click 7.1.2\n",
            "Adding click 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for itsdangerous==1.1.0\n",
            "Best match: itsdangerous 1.1.0\n",
            "Adding itsdangerous 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Jinja2==2.11.3\n",
            "Best match: Jinja2 2.11.3\n",
            "Adding Jinja2 2.11.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for docopt==0.6.2\n",
            "Best match: docopt 0.6.2\n",
            "Adding docopt 0.6.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pycparser==2.20\n",
            "Best match: pycparser 2.20\n",
            "Adding pycparser 2.20 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for appdirs==1.4.4\n",
            "Best match: appdirs 1.4.4\n",
            "Adding appdirs 1.4.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for packaging==21.0\n",
            "Best match: packaging 21.0\n",
            "Adding packaging 21.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2021.5.30\n",
            "Best match: certifi 2021.5.30\n",
            "Adding certifi 2021.5.30 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for MarkupSafe==2.0.1\n",
            "Best match: MarkupSafe 2.0.1\n",
            "Adding MarkupSafe 2.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for TTS==0.2.0\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'build-lib' will not be supported in future versions. Please use the underscore name 'build_lib' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'build-dir' will not be supported in future versions. Please use the underscore name 'build_dir' instead\n",
            "  % (opt, underscore_opt))\n",
            "running develop\n",
            "running egg_info\n",
            "writing TTS.egg-info/PKG-INFO\n",
            "writing dependency_links to TTS.egg-info/dependency_links.txt\n",
            "writing entry points to TTS.egg-info/entry_points.txt\n",
            "writing requirements to TTS.egg-info/requires.txt\n",
            "writing top-level names to TTS.egg-info/top_level.txt\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE.txt'\n",
            "writing manifest file 'TTS.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-3.7/TTS/tts/layers/glow_tts/monotonic_align/core.cpython-37m-x86_64-linux-gnu.so -> TTS/tts/layers/glow_tts/monotonic_align\n",
            "Creating /usr/local/lib/python3.7/dist-packages/TTS.egg-link (link to .)\n",
            "Removing TTS 0.2.0 from easy-install.pth file\n",
            "Adding TTS 0.2.0 to easy-install.pth file\n",
            "Installing tts script to /usr/local/bin\n",
            "Installing tts-server script to /usr/local/bin\n",
            "\n",
            "Installed /content/TTS\n",
            "Processing dependencies for TTS==0.2.0\n",
            "Searching for fsspec==2021.10.0\n",
            "Best match: fsspec 2021.10.0\n",
            "Adding fsspec 2021.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut==1.2.3\n",
            "Best match: gruut 1.2.3\n",
            "Adding gruut 1.2.3 to easy-install.pth file\n",
            "Installing gruut script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for unidic-lite==1.0.8\n",
            "Best match: unidic-lite 1.0.8\n",
            "Adding unidic-lite 1.0.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for mecab-python3==1.0.3\n",
            "Best match: mecab-python3 1.0.3\n",
            "Adding mecab-python3 1.0.3 to easy-install.pth file\n",
            "Installing mecab-py script to /usr/local/bin\n",
            "Installing mecab-py-info script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for coqpit==0.0.14\n",
            "Best match: coqpit 0.0.14\n",
            "Adding coqpit 0.0.14 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for anyascii==0.3.0\n",
            "Best match: anyascii 0.3.0\n",
            "Adding anyascii 0.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for umap-learn==0.5.1\n",
            "Best match: umap-learn 0.5.1\n",
            "Adding umap-learn 0.5.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numba==0.53.0\n",
            "Best match: numba 0.53.0\n",
            "Adding numba 0.53.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.62.3\n",
            "Best match: tqdm 4.62.3\n",
            "Adding tqdm 4.62.3 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torch==1.9.0+cu102\n",
            "Best match: torch 1.9.0+cu102\n",
            "Adding torch 1.9.0+cu102 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboardX==2.4\n",
            "Best match: tensorboardX 2.4\n",
            "Adding tensorboardX 2.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for SoundFile==0.10.3.post1\n",
            "Best match: SoundFile 0.10.3.post1\n",
            "Adding SoundFile 0.10.3.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for PyYAML==3.13\n",
            "Best match: PyYAML 3.13\n",
            "Adding PyYAML 3.13 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pysbd==0.3.4\n",
            "Best match: pysbd 0.3.4\n",
            "Adding pysbd 0.3.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pypinyin==0.42.1\n",
            "Best match: pypinyin 0.42.1\n",
            "Adding pypinyin 0.42.1 to easy-install.pth file\n",
            "Installing pypinyin script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pandas==1.1.5\n",
            "Best match: pandas 1.1.5\n",
            "Adding pandas 1.1.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for matplotlib==3.2.2\n",
            "Best match: matplotlib 3.2.2\n",
            "Adding matplotlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for librosa==0.8.0\n",
            "Best match: librosa 0.8.0\n",
            "Adding librosa 0.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for jieba==0.42.1\n",
            "Best match: jieba 0.42.1\n",
            "Adding jieba 0.42.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for inflect==2.1.0\n",
            "Best match: inflect 2.1.0\n",
            "Adding inflect 2.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gdown==3.6.4\n",
            "Best match: gdown 3.6.4\n",
            "Adding gdown 3.6.4 to easy-install.pth file\n",
            "Installing gdown script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Flask==1.1.4\n",
            "Best match: Flask 1.1.4\n",
            "Adding Flask 1.1.4 to easy-install.pth file\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Cython==0.29.24\n",
            "Best match: Cython 0.29.24\n",
            "Adding Cython 0.29.24 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-nl==1.2\n",
            "Best match: gruut-lang-nl 1.2\n",
            "Adding gruut-lang-nl 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-es==1.2\n",
            "Best match: gruut-lang-es 1.2\n",
            "Adding gruut-lang-es 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-ru==1.2\n",
            "Best match: gruut-lang-ru 1.2\n",
            "Adding gruut-lang-ru 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-pt==1.2\n",
            "Best match: gruut-lang-pt 1.2\n",
            "Adding gruut-lang-pt 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-cs==1.2\n",
            "Best match: gruut-lang-cs 1.2\n",
            "Adding gruut-lang-cs 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-de==1.2\n",
            "Best match: gruut-lang-de 1.2\n",
            "Adding gruut-lang-de 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-sv==1.2\n",
            "Best match: gruut-lang-sv 1.2\n",
            "Adding gruut-lang-sv 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-fr==1.2.1\n",
            "Best match: gruut-lang-fr 1.2.1\n",
            "Adding gruut-lang-fr 1.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-lang-it==1.2\n",
            "Best match: gruut-lang-it 1.2\n",
            "Adding gruut-lang-it 1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for gruut-ipa==0.9.3\n",
            "Best match: gruut-ipa 0.9.3\n",
            "Adding gruut-ipa 0.9.3 to easy-install.pth file\n",
            "Installing gruut-ipa script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for num2words==0.5.10\n",
            "Best match: num2words 0.5.10\n",
            "Adding num2words 0.5.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-crfsuite==0.9.7\n",
            "Best match: python-crfsuite 0.9.7\n",
            "Adding python-crfsuite 0.9.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Babel==2.8.1\n",
            "Best match: Babel 2.8.1\n",
            "Adding Babel 2.8.1 to easy-install.pth file\n",
            "Installing pybabel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for jsonlines==1.2.0\n",
            "Best match: jsonlines 1.2.0\n",
            "Adding jsonlines 1.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scikit-learn==0.22.2.post1\n",
            "Best match: scikit-learn 0.22.2.post1\n",
            "Adding scikit-learn 0.22.2.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pynndescent==0.5.4\n",
            "Best match: pynndescent 0.5.4\n",
            "Adding pynndescent 0.5.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for setuptools==57.4.0\n",
            "Best match: setuptools 57.4.0\n",
            "Adding setuptools 57.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for llvmlite==0.36.0\n",
            "Best match: llvmlite 0.36.0\n",
            "Adding llvmlite 0.36.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==3.7.4.3\n",
            "Best match: typing-extensions 3.7.4.3\n",
            "Adding typing-extensions 3.7.4.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for protobuf==3.17.3\n",
            "Best match: protobuf 3.17.3\n",
            "Adding protobuf 3.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cffi==1.14.6\n",
            "Best match: cffi 1.14.6\n",
            "Adding cffi 1.14.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pytz==2018.9\n",
            "Best match: pytz 2018.9\n",
            "Adding pytz 2018.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyparsing==2.4.7\n",
            "Best match: pyparsing 2.4.7\n",
            "Adding pyparsing 2.4.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for kiwisolver==1.3.2\n",
            "Best match: kiwisolver 1.3.2\n",
            "Adding kiwisolver 1.3.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cycler==0.10.0\n",
            "Best match: cycler 0.10.0\n",
            "Adding cycler 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for joblib==1.0.1\n",
            "Best match: joblib 1.0.1\n",
            "Adding joblib 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for resampy==0.2.2\n",
            "Best match: resampy 0.2.2\n",
            "Adding resampy 0.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for audioread==2.1.9\n",
            "Best match: audioread 2.1.9\n",
            "Adding audioread 2.1.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for decorator==4.4.2\n",
            "Best match: decorator 4.4.2\n",
            "Adding decorator 4.4.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pooch==1.5.1\n",
            "Best match: pooch 1.5.1\n",
            "Adding pooch 1.5.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for itsdangerous==1.1.0\n",
            "Best match: itsdangerous 1.1.0\n",
            "Adding itsdangerous 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Jinja2==2.11.3\n",
            "Best match: Jinja2 2.11.3\n",
            "Adding Jinja2 2.11.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for click==7.1.2\n",
            "Best match: click 7.1.2\n",
            "Adding click 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for docopt==0.6.2\n",
            "Best match: docopt 0.6.2\n",
            "Adding docopt 0.6.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pycparser==2.20\n",
            "Best match: pycparser 2.20\n",
            "Adding pycparser 2.20 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for packaging==21.0\n",
            "Best match: packaging 21.0\n",
            "Adding packaging 21.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for appdirs==1.4.4\n",
            "Best match: appdirs 1.4.4\n",
            "Adding appdirs 1.4.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2021.5.30\n",
            "Best match: certifi 2021.5.30\n",
            "Adding certifi 2021.5.30 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for MarkupSafe==2.0.1\n",
            "Best match: MarkupSafe 2.0.1\n",
            "Adding MarkupSafe 2.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for TTS==0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpYNgqrZcJKn"
      },
      "source": [
        "## **TTS utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KZA4b_CbMqx"
      },
      "source": [
        "import sys\n",
        "TTS_PATH = \"TTS/\"\n",
        "# add libraries into environment\n",
        "sys.path.append(TTS_PATH) # set this if TTS is not installed globally\n",
        "\n",
        "import os\n",
        "import string\n",
        "import time\n",
        "import argparse\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "from TTS.tts.utils.synthesis import synthesis\n",
        "from TTS.tts.utils.text.symbols import make_symbols, phonemes, symbols\n",
        "try:\n",
        "  from TTS.utils.audio import AudioProcessor\n",
        "except:\n",
        "  from TTS.utils.audio import AudioProcessor\n",
        "\n",
        "\n",
        "from TTS.tts.models import setup_model\n",
        "from TTS.config import load_config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smvc4NpR7DKL"
      },
      "source": [
        "# **Test Dataset Download**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdvQUtl97JLg",
        "outputId": "5723b6fe-dd69-4d80-895a-683499f38b21"
      },
      "source": [
        "! gdown  --id 140S0EcEZyCF0tF_uhY9wYSnJ1DqfByrX -O Test_dataset.zip\n",
        "! unzip -o Test_dataset.zip \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=140S0EcEZyCF0tF_uhY9wYSnJ1DqfByrX\n",
            "To: /content/Test_dataset.zip\n",
            "100% 49.6M/49.6M [00:00<00:00, 96.0MB/s]\n",
            "Archive:  Test_dataset.zip\n",
            "   creating: Test-Dataset/\n",
            "  inflating: Test-Dataset/new_se.json  \n",
            "   creating: Test-Dataset/VCTK/\n",
            "  inflating: Test-Dataset/VCTK/MOS-test-sentences.txt  \n",
            "   creating: Test-Dataset/VCTK/VCTK_references/\n",
            "  inflating: Test-Dataset/VCTK/VCTK_references/p225_005.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK_references/p347_005.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK_references/p326_005.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK_references/p294_005.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK_references/p245_005.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK_references/p335_005.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK_references/p302_005.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK_references/p234_005.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK_references/p261_005.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK_references/p248_005.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK_references/p238_005.wav  \n",
            "   creating: Test-Dataset/VCTK/VCTK-Ground-Truth/\n",
            "   creating: Test-Dataset/VCTK/VCTK-Ground-Truth/p347/\n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p347/p347_315.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p347/p347_058.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p347/p347_127.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p347/p347_098.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p347/p347_151.wav  \n",
            "   creating: Test-Dataset/VCTK/VCTK-Ground-Truth/p335/\n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p335/p335_037.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p335/p335_359.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p335/p335_154.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p335/p335_022.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p335/p335_335.wav  \n",
            "   creating: Test-Dataset/VCTK/VCTK-Ground-Truth/p294/\n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p294/p294_398.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p294/p294_396.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p294/p294_338.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p294/p294_050.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p294/p294_201.wav  \n",
            "   creating: Test-Dataset/VCTK/VCTK-Ground-Truth/p302/\n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p302/p302_144.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p302/p302_272.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p302/p302_114.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p302/p302_052.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p302/p302_184.wav  \n",
            "   creating: Test-Dataset/VCTK/VCTK-Ground-Truth/p238/\n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p238/p238_104.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p238/p238_419.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p238/p238_425.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p238/p238_069.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p238/p238_262.wav  \n",
            "   creating: Test-Dataset/VCTK/VCTK-Ground-Truth/p326/\n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p326/p326_274.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p326/p326_061.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p326/p326_311.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p326/p326_205.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p326/p326_271.wav  \n",
            "   creating: Test-Dataset/VCTK/VCTK-Ground-Truth/p245/\n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p245/p245_329.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p245/p245_029.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p245/p245_214.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p245/p245_044.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p245/p245_074.wav  \n",
            "   creating: Test-Dataset/VCTK/VCTK-Ground-Truth/p234/\n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p234/p234_164.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p234/p234_189.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p234/p234_176.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p234/p234_234.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p234/p234_069.wav  \n",
            "   creating: Test-Dataset/VCTK/VCTK-Ground-Truth/p248/\n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p248/p248_321.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p248/p248_274.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p248/p248_042.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p248/p248_033.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p248/p248_164.wav  \n",
            "   creating: Test-Dataset/VCTK/VCTK-Ground-Truth/p261/\n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p261/p261_064.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p261/p261_164.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p261/p261_113.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p261/p261_378.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p261/p261_155.wav  \n",
            "   creating: Test-Dataset/VCTK/VCTK-Ground-Truth/p225/\n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p225/p225_314.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p225/p225_166.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p225/p225_007.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p225/p225_310.wav  \n",
            "  inflating: Test-Dataset/VCTK/VCTK-Ground-Truth/p225/p225_064.wav  \n",
            "   creating: Test-Dataset/LibriTTS/\n",
            "   creating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/\n",
            "   creating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/121_f/\n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/121_f/121_121726_000034_000001.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/121_f/121_121726_000025_000001.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/121_f/121_121726_000005_000001.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/121_f/121_121726_000029_000003.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/121_f/121_121726_000025_000000.wav  \n",
            "   creating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/237_f/\n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/237_f/237_126133_000049_000000.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/237_f/237_126133_000005_000000.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/237_f/237_126133_000014_000001.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/237_f/237_126133_000023_000000.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/237_f/237_126133_000002_000003.wav  \n",
            "   creating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/260_m/\n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/260_m/260_123286_000061_000006.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/260_m/260_123286_000058_000001.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/260_m/260_123286_000045_000002.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/260_m/260_123286_000024_000000.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/260_m/260_123286_000040_000000.wav  \n",
            "   creating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/908_m/\n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/908_m/908_31957_000017_000002.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/908_m/908_157963_000034_000000.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/908_m/908_157963_000004_000000.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/908_m/908_31957_000011_000001.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/908_m/908_31957_000007_000000.wav  \n",
            "   creating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1089_m/\n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1089_m/1089_134686_000014_000003.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1089_m/1089_134686_000002_000004.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1089_m/1089_134686_000011_000002.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1089_m/1089_134686_000034_000003.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1089_m/1089_134686_000024_000001.wav  \n",
            "   creating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1188_m/\n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1188_m/1188_133604_000011_000003.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1188_m/1188_133604_000012_000004.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1188_m/1188_133604_000021_000003.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1188_m/1188_133604_000033_000001.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1188_m/1188_133604_000018_000002.wav  \n",
            "   creating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1284_f/\n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1284_f/1284_1180_000024_000001.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1284_f/1284_1180_000004_000004.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1284_f/1284_1180_000007_000000.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1284_f/1284_1180_000008_000001.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1284_f/1284_1180_000006_000002.wav  \n",
            "   creating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1580_f/\n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1580_f/1580_141083_000006_000002.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1580_f/1580_141083_000015_000003.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1580_f/1580_141083_000009_000004.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1580_f/1580_141083_000006_000001.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1580_f/1580_141083_000061_000001.wav  \n",
            "   creating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1995_f/\n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1995_f/1995_1826_000004_000003.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1995_f/1995_1826_000005_000003.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1995_f/1995_1826_000016_000001.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1995_f/1995_1826_000016_000012.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1995_f/1995_1826_000042_000000.wav  \n",
            "   creating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/2300_m/\n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/2300_m/2300_131720_000023_000000.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/2300_m/2300_131720_000033_000008.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/2300_m/2300_131720_000032_000000.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/2300_m/2300_131720_000021_000001.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/2300_m/2300_131720_000005_000005.wav  \n",
            "   creating: Test-Dataset/LibriTTS/LibriTTS_references/\n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_references/121_121726_000004_000003.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_references/237_126133_000004_000000.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_references/260_123286_000032_000002.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_references/908_31957_000025_000001.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_references/1089_134686_000008_000000.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_references/1188_133604_000006_000000.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_references/1284_1180_000005_000001.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_references/1580_141083_000001_000002.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_references/1995_1826_000018_000004.wav  \n",
            "  inflating: Test-Dataset/LibriTTS/LibriTTS_references/2300_131720_000012_000002.wav  \n",
            "   creating: Test-Dataset/MLS_PT/\n",
            "   creating: Test-Dataset/MLS_PT/Ground-Truth/\n",
            "   creating: Test-Dataset/MLS_PT/Ground-Truth/3050/\n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/3050/3050_2941_000003.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/3050/3050_2941_000011.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/3050/3050_2941_000012.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/3050/3050_2941_000002.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/3050/3050_2941_000010.wav  \n",
            "   creating: Test-Dataset/MLS_PT/Ground-Truth/12710/\n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/12710/12710_10229_000015.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/12710/12710_10229_000003.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/12710/12710_10229_000008.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/12710/12710_10229_000004.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/12710/12710_10229_000012.wav  \n",
            "   creating: Test-Dataset/MLS_PT/Ground-Truth/4367/\n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/4367/4367_5323_000002.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/4367/4367_4272_000413.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/4367/4367_4272_000607.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/4367/4367_3698_000029.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/4367/4367_4572_000124.wav  \n",
            "   creating: Test-Dataset/MLS_PT/Ground-Truth/5677/\n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/5677/5677_4807_000009.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/5677/5677_4807_000309.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/5677/5677_4807_000051.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/5677/5677_4807_000251.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/5677/5677_4807_000098.wav  \n",
            "   creating: Test-Dataset/MLS_PT/Ground-Truth/7925/\n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/7925/7925_6390_000003.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/7925/7925_6390_000008.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/7925/7925_6390_000004.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/7925/7925_6390_000001.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/7925/7925_6390_000009.wav  \n",
            "   creating: Test-Dataset/MLS_PT/Ground-Truth/9351/\n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/9351/9351_9018_000296.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/9351/9351_9018_000231.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/9351/9351_9018_000194.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/9351/9351_9018_000209.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/9351/9351_9018_000354.wav  \n",
            "   creating: Test-Dataset/MLS_PT/Ground-Truth/11995/\n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/11995/11995_10229_000003.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/11995/11995_10229_000002.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/11995/11995_10229_000005.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/11995/11995_10229_000004.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/11995/11995_10229_000008.wav  \n",
            "   creating: Test-Dataset/MLS_PT/Ground-Truth/12249/\n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/12249/12249_12879_000544.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/12249/12249_12879_000417.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/12249/12249_12879_000387.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/12249/12249_12879_000708.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/12249/12249_12879_000394.wav  \n",
            "   creating: Test-Dataset/MLS_PT/Ground-Truth/12287/\n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/12287/12287_12742_000003.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/12287/12287_12742_000004.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/12287/12287_12742_000001.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/12287/12287_12742_000010.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/12287/12287_12742_000008.wav  \n",
            "   creating: Test-Dataset/MLS_PT/Ground-Truth/13069/\n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/13069/13069_13511_000005.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/13069/13069_13511_000006.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/13069/13069_13511_000010.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/13069/13069_13511_000012.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/Ground-Truth/13069/13069_13511_000013.wav  \n",
            "   creating: Test-Dataset/MLS_PT/references/\n",
            "  inflating: Test-Dataset/MLS_PT/references/12249_12765_000220.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/references/12287_12742_000007.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/references/3050_2941_000034.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/references/9351_9018_000173.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/references/11995_10229_000007.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/references/4367_4272_000319.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/references/5677_4807_000094.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/references/7925_6390_000006.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/references/12710_10229_000006.wav  \n",
            "  inflating: Test-Dataset/MLS_PT/references/13069_13511_000007.wav  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgQ1ZILTZRcn"
      },
      "source": [
        "# Download general config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaNl2-FpZdxq",
        "outputId": "37e59f8c-a99e-4237-879c-0019b68a1e36"
      },
      "source": [
        "# download config   \n",
        "! gdown --id  1-PfXD66l1ZpsZmJiC-vhL055CDSugLyP\n",
        "# download language json \n",
        "! gdown --id 1_Vb2_XHqcC0OcvRF82F883MTxfTRmerg\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-PfXD66l1ZpsZmJiC-vhL055CDSugLyP\n",
            "To: /content/config.json\n",
            "100% 12.3k/12.3k [00:00<00:00, 10.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_Vb2_XHqcC0OcvRF82F883MTxfTRmerg\n",
            "To: /content/language_ids.json\n",
            "100% 47.0/47.0 [00:00<00:00, 132kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTO1pVsiZoXK"
      },
      "source": [
        "#  SECS Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFcBmfwuRWDt"
      },
      "source": [
        "Setences_per_speaker = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "id": "NU0GLTskZ6sf",
        "outputId": "5c526865-04ed-443e-be87-320562b44bad"
      },
      "source": [
        "! pip install resemblyzer\n",
        "! pip install pydub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting resemblyzer\n",
            "  Downloading Resemblyzer-0.1.1.dev0-py3-none-any.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 172 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from resemblyzer) (1.9.0+cu111)\n",
            "Collecting typing\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting webrtcvad>=2.0.10\n",
            "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from resemblyzer) (1.4.1)\n",
            "Requirement already satisfied: librosa>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from resemblyzer) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.7/dist-packages (from resemblyzer) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (1.0.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (0.51.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (21.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (0.22.2.post1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (0.2.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (1.5.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (0.10.3.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (2.1.9)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.6.1->resemblyzer) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.6.1->resemblyzer) (57.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa>=0.6.1->resemblyzer) (2.4.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.6.1->resemblyzer) (2.23.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.6.1->resemblyzer) (1.4.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa>=0.6.1->resemblyzer) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa>=0.6.1->resemblyzer) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.6.1->resemblyzer) (2.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.1->resemblyzer) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa>=0.6.1->resemblyzer) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa>=0.6.1->resemblyzer) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa>=0.6.1->resemblyzer) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa>=0.6.1->resemblyzer) (2021.5.30)\n",
            "Building wheels for collected packages: webrtcvad, typing\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp37-cp37m-linux_x86_64.whl size=72362 sha256=471ef9d70b2b83b9ea4d2d82c7b319294f78f8a50ab13c5a0f95b9ba7917c83f\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/f9/67/a3158d131f57e1c0a7d8d966a707d4a2fb27567a4fe47723ad\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26324 sha256=93d451ddd151f7512b1067ea9f99c6786e5e74d3491c64f7e34746a5ea702136\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/f3/15/01aa6571f0a72ee6ae7b827c1491c37a1f72d686fd22b43b0e\n",
            "Successfully built webrtcvad typing\n",
            "Installing collected packages: webrtcvad, typing, resemblyzer\n",
            "Successfully installed resemblyzer-0.1.1.dev0 typing-3.7.4.3 webrtcvad-2.0.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_NJqTTsZ75k",
        "outputId": "bdb7bc50-5bbd-4e2a-e5b5-efc5beb729c9"
      },
      "source": [
        "import os\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "import librosa\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from resemblyzer import VoiceEncoder, preprocess_wav\n",
        "\n",
        "from pydub import effects  \n",
        "from pydub import AudioSegment\n",
        "\n",
        "def cosine_similarity(x, y):\n",
        "    x = np.array(x).reshape(-1)\n",
        "    y = np.array(y).reshape(-1)\n",
        "    return np.dot(x, y) / (np.sqrt(np.dot(x, x)) * np.sqrt(np.dot(y, y)))\n",
        "\n",
        "encoder = VoiceEncoder()\n",
        "\n",
        "def compute_emb(path, normalize=True, target_dbfs=-27): #target_dbfs=-24.632442475923607\n",
        "    if normalize:\n",
        "      song = AudioSegment.from_file(path)\n",
        "      change_in_dBFS = target_dbfs - song.dBFS\n",
        "      normalized_sound = song.apply_gain(change_in_dBFS)\n",
        "      normalized_sound.export(path, format=path[-3:])\n",
        "\n",
        "    fpath = Path(path)\n",
        "    wav = preprocess_wav(fpath)\n",
        "    embed = encoder.embed_utterance(wav)\n",
        "    # print(embed.shape)\n",
        "    return embed\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cuda in 0.01 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68ZS_SpaRZ2A"
      },
      "source": [
        "import scipy.stats as st\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed=42):\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.random.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  # torch.set_deterministic(True)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def show_result(similarity):\n",
        "  print(\"Results:\")\n",
        "  all_secs = []         \n",
        "  for key in similarity.keys():\n",
        "    speaker_secs = np.array(similarity[key]).mean()\n",
        "    low_b, high_b = st.t.interval(0.95, len(similarity[key])-1, loc=speaker_secs, scale=st.sem(similarity[key]))\n",
        "    confience_interval_more_less = round(speaker_secs-low_b, 4)\n",
        "    print(\"Speaker:\", key, \"SECS:\", speaker_secs, \"+-\", confience_interval_more_less)\n",
        "    all_secs += similarity[key]\n",
        "\n",
        "  secs_all = np.array(all_secs).mean()\n",
        "  low_b, high_b = st.t.interval(0.95, len(all_secs)-1, loc=secs_all, scale=st.sem(all_secs))\n",
        "  confience_interval_more_less = round(secs_all-low_b, 4)\n",
        "  print(\"All SECS:\", secs_all, \"+-\", confience_interval_more_less)\n",
        "\n",
        "def compute_SECS_and_save_audios(references, Dataset_path, OUTPUT_WAV_PATH, language_id, Test_sentences): \n",
        "  # set seed for reproducibility\n",
        "  set_seed()\n",
        "  similarity = {}\n",
        "  setence_idx = 0\n",
        "  for ref in references:\n",
        "      ref_wav_path = os.path.join(Dataset_path, ref)\n",
        "      ref_wav, ref_sr = librosa.load(ref_wav_path, sr=16000)\n",
        "      print(\"Emb reference\")\n",
        "      IPython.display.display(Audio(ref_wav, rate=ref_sr))\n",
        "\n",
        "      ref_emb = compute_emb(ref_wav_path, normalize=False)\n",
        "\n",
        "      d_vector = model.speaker_manager.get_d_vector_by_clip(ref)\n",
        "      speaker_name = ref.split(\"_\")[0]\n",
        "      print(\"Synthesize sentence with Speaker: \", speaker_name)\n",
        "      first = False\n",
        "      spk_num_setences = 0\n",
        "\n",
        "      for _ in range(len(Test_sentences)):\n",
        "        # syn just 5 samples per speaker\n",
        "        if spk_num_setences >= Setences_per_speaker:\n",
        "          continue\n",
        "        TEXT = Test_sentences[setence_idx]\n",
        "\n",
        "        wav, alignment, _, _ = synthesis(\n",
        "                            model,\n",
        "                            TEXT,\n",
        "                            C,\n",
        "                            \"cuda\" in str(next(model.parameters()).device),\n",
        "                            ap,\n",
        "                            speaker_id=None,\n",
        "                            d_vector=d_vector,\n",
        "                            style_wav=None,\n",
        "                            language_id=language_id,\n",
        "                            enable_eos_bos_chars=C.enable_eos_bos_chars,\n",
        "                            use_griffin_lim=True,\n",
        "                            do_trim_silence=False).values()\n",
        "        if not first:\n",
        "          print(\"Generated Speech\")\n",
        "          IPython.display.display(Audio(wav, rate=ap.sample_rate))\n",
        "          first = True\n",
        "        # save the results\n",
        "        out_path = os.path.join(OUTPUT_WAV_PATH, speaker_name+'_'+str(setence_idx)+'.wav')\n",
        "        ap.save_wav(wav, out_path)\n",
        "        syn_emb = compute_emb(out_path)\n",
        "        secs = cosine_similarity(ref_emb, syn_emb)\n",
        "        # print(\"SECS:\", secs)\n",
        "        if speaker_name in similarity.keys():\n",
        "          similarity[speaker_name] += [secs]\n",
        "        else:\n",
        "          similarity[speaker_name] = [secs]\n",
        "        \n",
        "        setence_idx += 1\n",
        "        spk_num_setences += 1\n",
        "        if setence_idx >= len(Test_sentences):\n",
        "          setence_idx = 0\n",
        "\n",
        "  show_result(similarity)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNeWrpUKaUqR"
      },
      "source": [
        "# Test sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyxhhK8baYC8"
      },
      "source": [
        "Portuguese_test_sentences = [\"Se você pensava que eu morava em São Paulo por que você não veio me ver ? A senhora perguntou .\",\n",
        "\"Ele pensou que tinha sentido um cheiro agradável de ervas como as que a sua mãe tinha na casa dela .\",\n",
        "\"Quando subimos eu disse ao João para fechar a porta do banco que eles tinham deixado aberta na pressa .\",\n",
        "\"Esta é a minha escolaridade senhor e se alguém negligenciar esse livro há pouca chance de aprender com as terras abertas da Providência.\",\n",
        "\"Muita miséria e desconforto serão suportados antes que a última bugiganga ou a última pretensão de decência seja posta de lado.\",\n",
        "\"Eu sabia que você não poderia escolher não gostar dela porém ainda assim acho que você só viu o pior dela.\",\n",
        "\"Pedro entretanto tendo voltado para casa e perdido o crucifixo adivinhou quem o havia levado seu crucifixo, porém não se preocupou com isso.\",\n",
        "\"O decreto de terras do Congresso dos soviéticos é idêntico em seus fundamentos às decisões do primeiro Congresso dos Camponeses.\",\n",
        "\"Meu novo amigo era um poeta como eu, ele era um admirador da literatura italiana, enquanto eu admirava a literatura francesa.\",\n",
        "\"Seu credo prevê a proteção de todos os homens em seus direitos de culto de acordo com as normas da constituição.\",\n",
        "\"Por mais que as circunstâncias externas pudessem se opor a isso, ele agora sentia, com uma certeza absoluta, que essa obra não era dele.\",\n",
        "\"Achei que estávamos perplexos de novo quando vi aquela foto pela primeira vez, mas ela tem sido útil, afinal.\",\n",
        "\"Sua alma desmaiava em um novo mundo, fantástico, sombrio, incerto como o fundo do mar, atravessado por seres sombrios.\",\n",
        "\"Contigo vaguei pelos mundos mais remotos e frios, como um fantasma que assombra voluntariamente os telhados de inverno e as neves.\",\n",
        "\"Então o Pedro começou a falar bem e a dizer, ó meu senhor, pegue esta bolsa e venha comigo.\",\n",
        "\"Paulo também, depois de ter experimentado boa e má sorte por um longo tempo, jogou as armas no chão e saiu do reino.\",\n",
        "\"Maria teve que lidar com um partido poderoso em Israel que favorecia o restabelecimento do reino de Gabriel na Palestina.\",\n",
        "\"Se tivessem uma maior consideração tivesse ao resultado, a senhora Ana certamente não teria sido reprovada.\",\n",
        "\"Imediatamente o sorridente João começou a gritar de tanto rir, de modo que os sinos em seu boné começaram a tocar.\",\n",
        "\"É melhor morar no mar e deixar que outros homens façam suas plantações e preparem suas refeições.\",\n",
        "\"O marquês de Caxias, um homem com mais de oitenta e quatro anos, foi o último na Inglaterra a se submeter à autoridade do parlamento.\",\n",
        "\"Anderson disse com um suspiro, faça o que quiser, meu caro senhor, pois seus argumentos estão além de meus poderes de refutação.\",\n",
        "\"Vou descrever eles brevemente, e você deve ler o relato deles nos registros sagrados.\",\n",
        "\"Ninguém pode resistir ao Poderoso Rei da Inglaterra, por isso é tolice se rebelar contra seus comandos.\",\n",
        "\"As ferrovias não haviam chegado ao condado de São Vicente e a caça selvagem era abundante na fazenda do meu pai.\",\n",
        "\"Não sei como, mas você deve manter o assunto em mente e talvez a chance chegue a você, ela respondeu.\",\n",
        "\"A entrada do rei e a estimativa de seus atrasos são dois pontos importantes que ainda devem ser acertados com aquela nação.\",\n",
        "\"Porquê esses senhores estão aqui? perguntou Pedro, apontando para o cavalheiro, que falava na mesa principal.\",\n",
        "\"Ela ficou acordada por muito tempo esta noite, planejando  como diminuir a influência maligna da vida de Milton sobre sua mãe.\",\n",
        "\"Ó vida desta nossa fonte! Por que desvanece o lótus da água? Por que desvanece estes filhos da primavera?\",\n",
        "\"Pobre Gabriel! A natureza dele recuou diante do engano, e ele disse, em todo caso, tanto da verdade quanto ousou.\",\n",
        "\"Percebe-se, sem entender, um murmúrio que soa quase como sotaque humano, porém se assemelha muito mais a um grito do que a uma palavra articulada.\",\n",
        "\"Ele conhecia bem os perigos da fronteira, o estado selvagem da sociedade, os índios à espreita e os perigos da febre.\",\n",
        "\"Na parte mais baixa da montanha que separava os dois países, o caminho se dividia em dois.\",\n",
        "\"O rapaz tinha trinta anos, e a idade de seu chefe era quinze para vinte anos.\",\n",
        "\"Meu pai também perdeu o pai dele, e meu irmão mais velho, mas todos nós parecemos pessoas ressuscitadas.\",\n",
        "\"Não, eu fiquei bastante emocionado, desconfiando de toda luz que parecia dourar o caminho para a frente, e temia até mesmo recobrir um dedo.\",\n",
        "\"Ele sabia agora que sua ausência no tempo que ele precisasse ficar fora, seria acobertada e devidamente contabilizada.\",\n",
        "\"Ela disse: Vou te mostrar o bom trabalho que fiz. Então ela foi até um armário alto e abriu as portas.\",\n",
        "\"Então ele reapareceu, rastejando ao longo da terra, da qual seu vestido mal se distinguia, diretamente nas costas de seu prisioneiro.\",\n",
        "\"Os soldados amedrontados correram para capturar Pedro, e João ficou muito satisfeito porque sabia que Pedro a essa altura estava bem escondido.\",\n",
        "\"Então ele me concedeu grandes riquezas de seus tesouros e me deu um presente magnífico durante a comemoração\",\n",
        "\"Ele não deu atenção para ela olhou para mim, mas como se, em vez de mim, ouvisse oque ela falava.\",\n",
        "\"Tenho um remédio contra a sede, que é ao contrário do que é bom contra morder um cachorro louco.\",\n",
        "\"Enquanto planejávamos a invasão, pretendíamos que eu fosse um dos ladrões a entrar no banco.\",\n",
        "\"Afinal, o povo considera o advento do exército da nação uma das maiores bênçãos materiais já concedidas a eles.\",\n",
        "\"Não sabes que esta senhora é a esposa do camareiro e que ela pretende castigar você por perturbar ela?\",\n",
        "\"Só que, embora o amor tenha desaparecido totalmente, ela ainda reclama carinho, e ela não queria perder o respeito e afeto de Vitor.\",\n",
        "\"O silêncio nunca dura muito, no entanto, porque o desejo feminino de conversar sobre isso geralmente vence a emoção mais profunda.\",\n",
        "\"Até agora, o animal universal foi feito à imagem divina, mas os outros animais ainda não foram incluídos nele.\",\n",
        "\"Mas você não deve comer com o boné na cabeça, disse ela, e removou o bobé dele.\",\n",
        "\"Eu me entrego para ser um verdadeiro prisioneiro respondi para Maria, em tom de submissão.\",\n",
        "\"Se meu irmão diz certamente eu devo fazer isso, disse a filha do homem, e ela jogou o caixão no mar.\",\n",
        "\"Os lojistas e algumas das pessoas menos infelizes de lá protestaram alto o suficiente para voltar à Terra.\",\n",
        "\"Não vai ser muito, mas estou grato por encontrar um amigo. Sou culpado, você sabe, e não há ninguém para culpar a não ser eu mesmo.\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZXQJ8waaqUf"
      },
      "source": [
        "English_test_sentences = [\"If you thought I lived in New York, why in the world didn't you come and see me ? the lady inquired.\",\n",
        "\"He thought he detected a pleasant smell of herbs, like the potpourri his mother had in bowls in their house.\",\n",
        "\"When we came up I told Miller to shut the bank door, which they had left open in their hurry.\",\n",
        "\"This is my schooling, major; and if one neglects the book, there is little chance of learning from the open land of Providence.\",\n",
        "\"Very much of squalor and discomfort will be endured before the last trinket or the last pretense of pecuniary decency is put away.\",\n",
        "\"I knew you could not choose but like her; but yet, let me tell you, you have seen but the worst of her.\",\n",
        "\"Rodolfo meanwhile having returned home, and having missed the crucifix, guessed who had taken it, but gave himself no concern about it.\",\n",
        "\"The Land decree of the Congress of Soviets is identical in its fundamentals with the decisions of the first Peasants' Congress.\",\n",
        "\"My new friend was a poet as I was; he was an admirer of Italian literature, while I admired the French.\",\n",
        "\"Its creed provides for the protection of all men in their rights of worship according to the dictates of conscience.\",\n",
        "\"However loudly outward circumstances might oppose this, he now felt, with a certainty which surprised him, that this work was not his own.\",\n",
        "\"I thought we were 'stumped' again when I first saw that picture, but it's been of some use, after all.\",\n",
        "\"His soul was swooning into some new world, fantastic, dim, uncertain as under sea, traversed by cloudy shapes and beings.\",\n",
        "\"With thee have I wandered about in the remotest, coldest worlds, like a phantom that voluntarily haunteth winter roofs and snows.\",\n",
        "\"So the Castrato began to speak him fair and say to him, O my lord, take this purse and go with me.\",\n",
        "\"Montrose also, after having experienced still more variety of good and bad fortune, threw down his arms, and retired out of the kingdom.\",\n",
        "\"Pekah had to deal with a powerful party in Israel which favoured the re establishment of David's kingdom in Palestine.\",\n",
        "\"Whether much or little consideration had been directed to the result, Miss Chancellor certainly would not have incurred this reproach.\",\n",
        "\"Forthwith the grinning Jester began shrieking with laughter, so that the bells upon his motley cap were all set a jangling.\",\n",
        "\"Oh ! it is better to live on the sea and let other men raise your crops and cook your meals.\",\n",
        "\"The marquis of Worcester, a man past eighty four, was the last in England that submitted to the authority of the parliament.\",\n",
        "\"Well, said Franz with a sigh, do as you please my dear viscount, for your arguments are beyond my powers of refutation.\",\n",
        "\"I will briefly describe them to you, and you shall read the account of them at your leisure in the sacred registers.\",\n",
        "\"No one can resist the Mighty Boolooroo of the Blues, so it is folly for you to rebel against my commands.\",\n",
        "\"The railroads had not reached Jackson county, and wild game was plentiful on my father's farm on Big Creek near Lee's Summit.\",\n",
        "\"I do not know how, but you must keep the matter in mind and perhaps the chance will come to you, she replied.\",\n",
        "\"Two important points remained to be settled with that nation: their delivery of the king, and the estimation of their arrears.\",\n",
        "\"These gentlemen, now, what do they come for ? he said, pointing to the malignant gentleman, who was talking at the high table.\",\n",
        "\"She lay awake very long this night, planning how to lessen the evil influence of their Milton life on her mother.\",\n",
        "\"O life of this our spring ! why fades the lotus of the water ? Why fade these children of the spring ?\",\n",
        "\"Poor Rachel ! her nature recoiled from deceit, and she told, at all events, as much of the truth as she dared.\",\n",
        "\"One perceives, without understanding it, a hideous murmur, sounding almost like human accents, but more nearly resembling a howl than an articulate word.\",\n",
        "\"He well knew the perils of the frontier, the savage state of society, the lurking Indians and the dangers of fever.\",\n",
        "\"At the foot of the mountain that separated the Country of the Munchkins from the Country of the Gillikins, the path divided.\",\n",
        "\"The lad was thirty years old, and his age to that of his employer was as fifteen is to twenty.\",\n",
        "\"My father has lost his too, and my eldest brother, but we all look like people risen from the dead.\",\n",
        "\"Nay, I rather thrilled, Distrusting every light that seemed to gild The onward path, and feared to overlean A finger even.\",\n",
        "\"He knew now that his absence, for as long as he had to be away, would be covered up and satisfactorily accounted for.\",\n",
        "\"I will show you what a good job I did, and she went to a tall cupboard and threw open the doors.\",\n",
        "\"Then he reappeared, creeping along the earth, from which his dress was hardly distinguishable, directly in the rear of his intended captive.\",\n",
        "\"The frightened soldiers hurried away to find Tiggle, and Trot was well pleased because she knew Tiggle was by this time safely hidden.\",\n",
        "\"Then he bestowed on me great riches from his treasuries and charged me with a magnificent present for the Caliph Harun al Rashid.\",\n",
        "\"He took no notice of her; he looked at me, but as if, instead of me, he saw what he spoke of.\",\n",
        "\"I have a remedy against thirst, quite contrary to that which is good against the biting of a mad dog.\",\n",
        "\"While we were planning the raid it was intended that I should be one of the party to go into the bank.\",\n",
        "\"After all, the Mormon people regard the advent of the Buchanan army as one of the greatest material blessings ever brought to them.\",\n",
        "\"Dost thou not know that this lady is the wife; of the Chamberlain and is minded to chastise thee for disturbing her ?\",\n",
        "\"Only, even though love has wholly disappeared, she still claims consideration, and Althea did not wish to lose Hermon's regard.\",\n",
        "\"The silence never lasts long, however, for the feminine desire to talk it over usually gets the better of the deepest emotion.\",\n",
        "\"Thus far the universal animal was made in the divine image, but the other animals were not as yet included in him.\",\n",
        "\"But you must not eat with your cap on your head, she said, and was going to take it off.\",\n",
        "\"I yield me to be true prisoner, rescue or no rescue, then answered De Bracy, in a tone of sullen submission.\",\n",
        "\"'Well, if my brother says so, I must do it,' said the man's daughter, and she flung her casket into the sea.\",\n",
        "\"The shopkeepers, and some of the less unfortunate people there, had protested loud enough to reach clear back to Earth.\",\n",
        "\"It won't be much, but I'm grateful to find a friend. I'm guilty, you know, and there's no one to blame but myself.\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENA2OumIVeMA"
      },
      "source": [
        "# **Vars definitions**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPD0d_XpVXmY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "edde7787-57d6-46b7-f3d4-c63cd3b15fad"
      },
      "source": [
        "OUT_PATH = 'audios/'\n",
        "\n",
        "# create output path\n",
        "os.makedirs(OUT_PATH, exist_ok=True)\n",
        "\n",
        "# model vars \n",
        "MODEL_PATH = 'best_model.pth.tar'\n",
        "CONFIG_PATH = 'config.json'\n",
        "TTS_LANGUAGES = \"language_ids.json\"\n",
        "TTS_SPEAKERS = \"Test-Dataset/new_se.json\"\n",
        "USE_CUDA = torch.cuda.is_available()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ac9c2dee4c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mTTS_LANGUAGES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"language_ids.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mTTS_SPEAKERS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Test-Dataset/new_se.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mUSE_CUDA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV6cXXlfi72r"
      },
      "source": [
        "# **Instance TTS Model and utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4YJ1wb_dDIp"
      },
      "source": [
        "def load_model(model_path):\n",
        "  global model\n",
        "  cp = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "  # remove speaker encoder\n",
        "  model_weights = cp['model'].copy()\n",
        "  for key in list(model_weights.keys()):\n",
        "    if \"speaker_encoder\" in key:\n",
        "      del model_weights[key]\n",
        "\n",
        "  model.load_state_dict(model_weights)\n",
        "  model.eval()\n",
        "\n",
        "  if USE_CUDA:\n",
        "      model = model.cuda()\n",
        "\n",
        "  model.inference_noise_scale = 0.333 # defines the noise variance applied to the random z vector at inference.\n",
        "  model.inference_noise_scale_dp = 0.333 # defines the noise variance applied to the duration predictor z vector at inference.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1WgLFauWUPe",
        "outputId": "de56a1f0-8133-46ae-c329-75e33b96c7fd"
      },
      "source": [
        "# load the config\n",
        "C = load_config(CONFIG_PATH)\n",
        "\n",
        "# load the audio processor\n",
        "ap = AudioProcessor(**C.audio)\n",
        "\n",
        "speaker_embedding = None\n",
        "\n",
        "# synthesize voice\n",
        "use_griffin_lim = False\n",
        "\n",
        "C.model_args['d_vector_file'] = TTS_SPEAKERS\n",
        "C.model_args['use_speaker_encoder_as_loss'] = False\n",
        "\n",
        "model = setup_model(C)\n",
        "model.language_manager.set_language_ids_from_file(TTS_LANGUAGES)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Setting up Audio Processor...\n",
            " | > sample_rate:16000\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:False\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:45\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:False\n",
            " | > do_amp_to_db_mel:True\n",
            " | > stats_path:None\n",
            " | > base:2.718281828459045\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > Using model: vits\n",
            " > Speaker manager is loaded with 331 speakers: 1089_134686_000002_000004, 1089_134686_000008_000000, 1089_134686_000011_000002, 1089_134686_000014_000003, 1089_134686_000024_000001, 1089_134686_000034_000003, 11614_catholicmorals_33_stapleton_0076, 11614_catholicmorals_38_stapleton_0031, 11614_catholicmorals_41_stapleton_0032, 11614_catholicmorals_42_stapleton_0062, 11614_catholicmorals_83_stapleton_0034, 11614_catholicmorals_93_stapleton_0001, 11697_widowbarnaby_08_trollope_0002, 11697_widowbarnaby_19_trollope_0041, 11697_widowbarnaby_25_trollope_0200, 11697_widowbarnaby_26_trollope_0226, 11697_widowbarnaby_29_trollope_0214, 11697_widowbarnaby_37_trollope_0026, 1188_133604_000006_000000, 1188_133604_000011_000003, 1188_133604_000012_000004, 1188_133604_000018_000002, 1188_133604_000021_000003, 1188_133604_000033_000001, 11995_10229_000002, 11995_10229_000003, 11995_10229_000004, 11995_10229_000005, 11995_10229_000007, 11995_10229_000008, 121_121726_000004_000003, 121_121726_000005_000001, 121_121726_000025_000000, 121_121726_000025_000001, 121_121726_000029_000003, 121_121726_000034_000001, 12249_12765_000220, 12249_12879_000387, 12249_12879_000394, 12249_12879_000417, 12249_12879_000503, 12249_12879_000544, 12249_12879_000708, 12287_12742_000001, 12287_12742_000003, 12287_12742_000004, 12287_12742_000007, 12287_12742_000008, 12287_12742_000010, 12710_10229_000003, 12710_10229_000004, 12710_10229_000006, 12710_10229_000008, 12710_10229_000012, 12710_10229_000015, 12787_search_04_hill_0064, 12787_search_05_hill_0175, 12787_search_07_hill_0233, 12787_search_08_hill_0140, 12787_search_11_hill_0123, 12787_search_12_hill_0326, 1284_1180_000004_000004, 1284_1180_000005_000001, 1284_1180_000006_000002, 1284_1180_000007_000000, 1284_1180_000008_000001, 1284_1180_000024_000001, 13069_13511_000005, 13069_13511_000006, 13069_13511_000007, 13069_13511_000010, 13069_13511_000012, 13069_13511_000013, 1320_122612_000006_000001, 1320_122612_000023_000002, 1320_122612_000023_000003, 1320_122612_000038_000000, 1320_122612_000039_000003, 1320_122612_000044_000002, 1580_141083_000001_000002, 1580_141083_000006_000001, 1580_141083_000006_000002, 1580_141083_000009_000004, 1580_141083_000015_000003, 1580_141083_000061_000001, 1995_1826_000004_000003, 1995_1826_000005_000003, 1995_1826_000016_000001, 1995_1826_000016_000012, 1995_1826_000018_000004, 1995_1826_000042_000000, 2300_131720_000005_000005, 2300_131720_000012_000002, 2300_131720_000021_000001, 2300_131720_000023_000000, 2300_131720_000032_000000, 2300_131720_000033_000008, 237_126133_000002_000003, 237_126133_000004_000000, 237_126133_000005_000000, 237_126133_000014_000001, 237_126133_000023_000000, 237_126133_000049_000000, 260_123286_000024_000000, 260_123286_000032_000002, 260_123286_000040_000000, 260_123286_000045_000002, 260_123286_000058_000001, 260_123286_000061_000006, 2961_961_000004_000036, 2961_961_000011_000000, 2961_961_000020_000001, 2961_961_000022_000002, 2961_961_000023_000007, 2961_961_000024_000002, 3050_2941_000002, 3050_2941_000003, 3050_2941_000010, 3050_2941_000011, 3050_2941_000012, 3050_2941_000034, 4367_3698_000029, 4367_4272_000319, 4367_4272_000413, 4367_4272_000607, 4367_4572_000124, 4367_5323_000002, 5677_4807_000009, 5677_4807_000051, 5677_4807_000094, 5677_4807_000098, 5677_4807_000251, 5677_4807_000309, 6097_presentpictureofnsw_01_mann_0510, 6097_presentpictureofnsw_04_mann_0465, 6097_presentpictureofnsw_04_mann_0494, 6097_presentpictureofnsw_05_mann_0330, 6097_presentpictureofnsw_05_mann_0413, 6097_presentpictureofnsw_05_mann_0677, 6670_fourweirdtales_04_blackwood_0114, 6670_fourweirdtales_05_blackwood_0106, 6670_fourweirdtales_05_blackwood_0261, 6670_fourweirdtales_06_blackwood_0302, 6670_fourweirdtales_08_blackwood_0087, 6670_fourweirdtales_08_blackwood_0296, 6671_monsieurlecoq_2_12_gaboriau_0015, 6671_monsieurlecoq_2_12_gaboriau_0026, 6671_monsieurlecoq_2_19_gaboriau_0005, 6671_monsieurlecoq_2_24_gaboriau_0435, 6671_monsieurlecoq_2_35_gaboriau_0014, 6671_monsieurlecoq_2_53_gaboriau_0255, 7925_6390_000001, 7925_6390_000003, 7925_6390_000004, 7925_6390_000006, 7925_6390_000008, 7925_6390_000009, 8051_undergroundrailroad2_22_still_0182, 8051_undergroundrailroad2_25_still_0040, 8051_undergroundrailroad2_25_still_0058, 8051_undergroundrailroad2_25_still_0092, 8051_undergroundrailroad2_25_still_0205, 8051_undergroundrailroad2_26_still_0143, 9017_dartagnan01_20_dumas_0234, 9017_dartagnan01_32_dumas_0029, 9017_dartagnan01_41_dumas_0022, 9017_dartagnan01_43_dumas_0021, 9017_dartagnan01_52_dumas_0043, 9017_dartagnan01_60_dumas_0001, 908_157963_000004_000000, 908_157963_000034_000000, 908_31957_000007_000000, 908_31957_000011_000001, 908_31957_000017_000002, 908_31957_000025_000001, 9136_secondsight_04_leverson_0253, 9136_secondsight_05_leverson_0019, 9136_secondsight_05_leverson_0187, 9136_secondsight_14_leverson_0166, 9136_secondsight_18_leverson_0118, 9136_secondsight_28_leverson_0172, 92_livingalone_05_benson_0007, 92_livingalone_07_benson_0714, 92_livingalone_08_benson_0073, 92_livingalone_08_benson_0185, 92_livingalone_08_benson_0234, 92_livingalone_09_benson_0266, 9351_9018_000173, 9351_9018_000194, 9351_9018_000209, 9351_9018_000231, 9351_9018_000296, 9351_9018_000354, F014-0016, F014-0713, F014-0769, F014-0836, F014-0864, F014-0926, F023-0526, F023-0610, F023-0644, F023-0732, F023-0926, F023-0941, F024-0082, F024-0116, F024-0127, F024-0152, F024-0285, F024-0926, F026-0037, F026-0216, F026-0250, F026-0484, F026-0789, F026-0926, F044-0208, F044-0317, F044-0450, F044-0817, F044-0819, F044-0926, F045-0014, F045-0169, F045-0439, F045-0695, F045-0926, F045-0961, M000-0284, M000-0584, M000-0652, M000-0670, M000-0700, M000-0926, M015-0020, M015-0258, M015-0642, M015-0674, M015-0926, M015-0969, M027-0168, M027-0179, M027-0395, M027-0683, M027-0926, M027-0949, M037-0244, M037-0481, M037-0549, M037-0673, M037-0926, M037-0995, M040-0051, M040-0072, M040-0393, M040-0583, M040-0926, M040-0983, M043-0165, M043-0197, M043-0213, M043-0804, M043-0812, M043-0926, p225_005, p225_007, p225_064, p225_166, p225_310, p225_314, p234_005, p234_069, p234_164, p234_176, p234_189, p234_234, p238_005, p238_069, p238_104, p238_262, p238_419, p238_425, p245_005, p245_029, p245_044, p245_074, p245_214, p245_329, p248_005, p248_033, p248_042, p248_164, p248_274, p248_321, p261_005, p261_064, p261_113, p261_155, p261_164, p261_378, p294_005, p294_050, p294_201, p294_338, p294_396, p294_398, p302_005, p302_052, p302_114, p302_144, p302_184, p302_272, p326_005, p326_061, p326_205, p326_271, p326_274, p326_311, p335_005, p335_022, p335_037, p335_154, p335_335, p335_359, p347_005, p347_058, p347_098, p347_127, p347_151, p347_315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl_HVF8oTXJ5"
      },
      "source": [
        "# SECS Ground truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dCVmCWITXKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7ad1d9-eaae-476e-fd26-f19e917e3095"
      },
      "source": [
        "import scipy.stats as st\n",
        "\n",
        "reference_dataset_path = \"Test-Dataset/VCTK/VCTK_references/\"\n",
        "\n",
        "Dataset_path = \"Test-Dataset/VCTK/VCTK-Ground-Truth/\"\n",
        "\n",
        "speakers_dir = os.listdir(Dataset_path)\n",
        "\n",
        "print(\"English VCTK Results:\")\n",
        "similarity = {}\n",
        "for speaker in speakers_dir:\n",
        "    speaker_name = speaker\n",
        "    ref_name = speaker+\"_005.wav\"\n",
        "    ref_wav_path = os.path.join(reference_dataset_path, ref_name)\n",
        "    ref_emb = compute_emb(ref_wav_path)\n",
        "    for spk_file in os.listdir(os.path.join(Dataset_path, speaker)):\n",
        "      emb = compute_emb(os.path.join(Dataset_path, speaker, spk_file))\n",
        "      secs = cosine_similarity(ref_emb, emb)\n",
        "      #print(\"SECS:\", secs)\n",
        "      if speaker_name in similarity.keys():\n",
        "        similarity[speaker_name] += [secs]\n",
        "      else:\n",
        "        similarity[speaker_name] = [secs]\n",
        "\n",
        "\n",
        "\n",
        "all_secs = []         \n",
        "for key in similarity.keys():\n",
        "  speaker_secs = np.array(similarity[key]).mean()\n",
        "  low_b, high_b = st.t.interval(0.95, len(similarity[key])-1, loc=speaker_secs, scale=st.sem(similarity[key]))\n",
        "  confience_interval_more_less = round(speaker_secs-low_b, 4)\n",
        "  print(\"Speaker:\", key, \"SECS:\", speaker_secs, \"+-\", confience_interval_more_less)\n",
        "  all_secs += similarity[key]\n",
        "\n",
        "secs_all = np.array(all_secs).mean()\n",
        "low_b, high_b = st.t.interval(0.95, len(all_secs)-1, loc=secs_all, scale=st.sem(all_secs))\n",
        "confience_interval_more_less = round(secs_all-low_b, 4)\n",
        "print(\"All SECS:\", secs_all, \"+-\", confience_interval_more_less)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English VCTK Results:\n",
            "Speaker: p347 SECS: 0.86646235 +- 0.0459\n",
            "Speaker: p294 SECS: 0.84550035 +- 0.0944\n",
            "Speaker: p261 SECS: 0.8185341 +- 0.057\n",
            "Speaker: p234 SECS: 0.80682623 +- 0.0695\n",
            "Speaker: p225 SECS: 0.78651774 +- 0.1827\n",
            "Speaker: p238 SECS: 0.8549142 +- 0.036\n",
            "Speaker: p326 SECS: 0.8271964 +- 0.0406\n",
            "Speaker: p248 SECS: 0.79113984 +- 0.0813\n",
            "Speaker: p335 SECS: 0.831806 +- 0.0841\n",
            "Speaker: p245 SECS: 0.8691696 +- 0.0491\n",
            "Speaker: p302 SECS: 0.7686432 +- 0.0603\n",
            "All SECS: 0.82424647 +- 0.0184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Wxf6UpVBKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eb486f7-0c4a-42ba-c724-4a55d537231d"
      },
      "source": [
        "import scipy.stats as st\n",
        "\n",
        "reference_dataset_path = \"Test-Dataset/LibriTTS/LibriTTS_references/\"\n",
        "\n",
        "Dataset_path = \"Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/\"\n",
        "\n",
        "def get_reference_sample(speaker_name, reference_wav_samples):\n",
        "  for n in reference_wav_samples:\n",
        "    if speaker_name == n.split(\"_\")[0]:\n",
        "      return n\n",
        "\n",
        "reference_wav_samples = os.listdir(reference_dataset_path)\n",
        "speakers_dir = os.listdir(Dataset_path)\n",
        "\n",
        "print(\"English LibriTTS Results:\")\n",
        "similarity = {}\n",
        "for speaker in speakers_dir:\n",
        "    speaker_name = speaker.split(\"_\")[0]\n",
        "    ref_name = get_reference_sample(speaker_name, reference_wav_samples)\n",
        "    ref_wav_path = os.path.join(reference_dataset_path, ref_name)\n",
        "    ref_emb = compute_emb(ref_wav_path)\n",
        "    for spk_file in os.listdir(os.path.join(Dataset_path, speaker)):\n",
        "      emb = compute_emb(os.path.join(Dataset_path, speaker, spk_file))\n",
        "      secs = cosine_similarity(ref_emb, emb)\n",
        "      print(secs, ref_wav_path, os.path.join(Dataset_path, speaker, spk_file))\n",
        "      #print(\"SECS:\", secs)\n",
        "      if speaker_name in similarity.keys():\n",
        "        similarity[speaker_name] += [secs]\n",
        "      else:\n",
        "        similarity[speaker_name] = [secs]\n",
        "\n",
        "\n",
        "\n",
        "all_secs = []         \n",
        "for key in similarity.keys():\n",
        "  speaker_secs = np.array(similarity[key]).mean()\n",
        "  low_b, high_b = st.t.interval(0.95, len(similarity[key])-1, loc=speaker_secs, scale=st.sem(similarity[key]))\n",
        "  confience_interval_more_less = round(speaker_secs-low_b, 4)\n",
        "  print(\"Speaker:\", key, \"SECS:\", speaker_secs, \"+-\", confience_interval_more_less)\n",
        "  all_secs += similarity[key]\n",
        "\n",
        "secs_all = np.array(all_secs).mean()\n",
        "low_b, high_b = st.t.interval(0.95, len(all_secs)-1, loc=secs_all, scale=st.sem(all_secs))\n",
        "confience_interval_more_less = round(secs_all-low_b, 4)\n",
        "print(\"All SECS:\", secs_all, \"+-\", confience_interval_more_less)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English LibriTTS Results:\n",
            "0.90603083 Test-Dataset/LibriTTS/LibriTTS_references/260_123286_000032_000002.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/260_m/260_123286_000058_000001.wav\n",
            "0.9189691 Test-Dataset/LibriTTS/LibriTTS_references/260_123286_000032_000002.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/260_m/260_123286_000040_000000.wav\n",
            "0.8986226 Test-Dataset/LibriTTS/LibriTTS_references/260_123286_000032_000002.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/260_m/260_123286_000024_000000.wav\n",
            "0.8809172 Test-Dataset/LibriTTS/LibriTTS_references/260_123286_000032_000002.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/260_m/260_123286_000045_000002.wav\n",
            "0.88654214 Test-Dataset/LibriTTS/LibriTTS_references/260_123286_000032_000002.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/260_m/260_123286_000061_000006.wav\n",
            "0.94681627 Test-Dataset/LibriTTS/LibriTTS_references/1580_141083_000001_000002.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1580_f/1580_141083_000006_000002.wav\n",
            "0.9555187 Test-Dataset/LibriTTS/LibriTTS_references/1580_141083_000001_000002.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1580_f/1580_141083_000015_000003.wav\n",
            "0.93626416 Test-Dataset/LibriTTS/LibriTTS_references/1580_141083_000001_000002.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1580_f/1580_141083_000061_000001.wav\n",
            "0.95908296 Test-Dataset/LibriTTS/LibriTTS_references/1580_141083_000001_000002.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1580_f/1580_141083_000006_000001.wav\n",
            "0.94495094 Test-Dataset/LibriTTS/LibriTTS_references/1580_141083_000001_000002.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1580_f/1580_141083_000009_000004.wav\n",
            "0.9618879 Test-Dataset/LibriTTS/LibriTTS_references/1188_133604_000006_000000.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1188_m/1188_133604_000021_000003.wav\n",
            "0.9670969 Test-Dataset/LibriTTS/LibriTTS_references/1188_133604_000006_000000.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1188_m/1188_133604_000011_000003.wav\n",
            "0.9657931 Test-Dataset/LibriTTS/LibriTTS_references/1188_133604_000006_000000.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1188_m/1188_133604_000018_000002.wav\n",
            "0.95819265 Test-Dataset/LibriTTS/LibriTTS_references/1188_133604_000006_000000.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1188_m/1188_133604_000012_000004.wav\n",
            "0.9587153 Test-Dataset/LibriTTS/LibriTTS_references/1188_133604_000006_000000.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1188_m/1188_133604_000033_000001.wav\n",
            "0.87323475 Test-Dataset/LibriTTS/LibriTTS_references/121_121726_000004_000003.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/121_f/121_121726_000025_000000.wav\n",
            "0.9270073 Test-Dataset/LibriTTS/LibriTTS_references/121_121726_000004_000003.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/121_f/121_121726_000005_000001.wav\n",
            "0.8961283 Test-Dataset/LibriTTS/LibriTTS_references/121_121726_000004_000003.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/121_f/121_121726_000029_000003.wav\n",
            "0.91001093 Test-Dataset/LibriTTS/LibriTTS_references/121_121726_000004_000003.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/121_f/121_121726_000034_000001.wav\n",
            "0.8907995 Test-Dataset/LibriTTS/LibriTTS_references/121_121726_000004_000003.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/121_f/121_121726_000025_000001.wav\n",
            "0.9734563 Test-Dataset/LibriTTS/LibriTTS_references/1089_134686_000008_000000.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1089_m/1089_134686_000014_000003.wav\n",
            "0.9718846 Test-Dataset/LibriTTS/LibriTTS_references/1089_134686_000008_000000.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1089_m/1089_134686_000002_000004.wav\n",
            "0.95378417 Test-Dataset/LibriTTS/LibriTTS_references/1089_134686_000008_000000.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1089_m/1089_134686_000011_000002.wav\n",
            "0.9254403 Test-Dataset/LibriTTS/LibriTTS_references/1089_134686_000008_000000.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1089_m/1089_134686_000024_000001.wav\n",
            "0.93590534 Test-Dataset/LibriTTS/LibriTTS_references/1089_134686_000008_000000.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1089_m/1089_134686_000034_000003.wav\n",
            "0.9180636 Test-Dataset/LibriTTS/LibriTTS_references/2300_131720_000012_000002.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/2300_m/2300_131720_000021_000001.wav\n",
            "0.9245785 Test-Dataset/LibriTTS/LibriTTS_references/2300_131720_000012_000002.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/2300_m/2300_131720_000023_000000.wav\n",
            "0.931312 Test-Dataset/LibriTTS/LibriTTS_references/2300_131720_000012_000002.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/2300_m/2300_131720_000032_000000.wav\n",
            "0.9549403 Test-Dataset/LibriTTS/LibriTTS_references/2300_131720_000012_000002.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/2300_m/2300_131720_000005_000005.wav\n",
            "0.91751665 Test-Dataset/LibriTTS/LibriTTS_references/2300_131720_000012_000002.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/2300_m/2300_131720_000033_000008.wav\n",
            "0.9248642 Test-Dataset/LibriTTS/LibriTTS_references/1995_1826_000018_000004.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1995_f/1995_1826_000005_000003.wav\n",
            "0.91905284 Test-Dataset/LibriTTS/LibriTTS_references/1995_1826_000018_000004.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1995_f/1995_1826_000004_000003.wav\n",
            "0.96012175 Test-Dataset/LibriTTS/LibriTTS_references/1995_1826_000018_000004.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1995_f/1995_1826_000042_000000.wav\n",
            "0.9568538 Test-Dataset/LibriTTS/LibriTTS_references/1995_1826_000018_000004.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1995_f/1995_1826_000016_000001.wav\n",
            "0.9327916 Test-Dataset/LibriTTS/LibriTTS_references/1995_1826_000018_000004.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1995_f/1995_1826_000016_000012.wav\n",
            "0.9507835 Test-Dataset/LibriTTS/LibriTTS_references/237_126133_000004_000000.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/237_f/237_126133_000049_000000.wav\n",
            "0.95774126 Test-Dataset/LibriTTS/LibriTTS_references/237_126133_000004_000000.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/237_f/237_126133_000002_000003.wav\n",
            "0.9549747 Test-Dataset/LibriTTS/LibriTTS_references/237_126133_000004_000000.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/237_f/237_126133_000005_000000.wav\n",
            "0.949271 Test-Dataset/LibriTTS/LibriTTS_references/237_126133_000004_000000.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/237_f/237_126133_000023_000000.wav\n",
            "0.94540274 Test-Dataset/LibriTTS/LibriTTS_references/237_126133_000004_000000.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/237_f/237_126133_000014_000001.wav\n",
            "0.8202181 Test-Dataset/LibriTTS/LibriTTS_references/908_31957_000025_000001.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/908_m/908_157963_000004_000000.wav\n",
            "0.9515514 Test-Dataset/LibriTTS/LibriTTS_references/908_31957_000025_000001.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/908_m/908_31957_000011_000001.wav\n",
            "0.9602043 Test-Dataset/LibriTTS/LibriTTS_references/908_31957_000025_000001.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/908_m/908_31957_000007_000000.wav\n",
            "0.93633455 Test-Dataset/LibriTTS/LibriTTS_references/908_31957_000025_000001.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/908_m/908_31957_000017_000002.wav\n",
            "0.87609893 Test-Dataset/LibriTTS/LibriTTS_references/908_31957_000025_000001.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/908_m/908_157963_000034_000000.wav\n",
            "0.94042706 Test-Dataset/LibriTTS/LibriTTS_references/1284_1180_000005_000001.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1284_f/1284_1180_000006_000002.wav\n",
            "0.9369418 Test-Dataset/LibriTTS/LibriTTS_references/1284_1180_000005_000001.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1284_f/1284_1180_000008_000001.wav\n",
            "0.8866263 Test-Dataset/LibriTTS/LibriTTS_references/1284_1180_000005_000001.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1284_f/1284_1180_000024_000001.wav\n",
            "0.93563914 Test-Dataset/LibriTTS/LibriTTS_references/1284_1180_000005_000001.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1284_f/1284_1180_000007_000000.wav\n",
            "0.9505812 Test-Dataset/LibriTTS/LibriTTS_references/1284_1180_000005_000001.wav Test-Dataset/LibriTTS/LibriTTS_Ground-Truth/1284_f/1284_1180_000004_000004.wav\n",
            "Speaker: 260 SECS: 0.8982164 +- 0.0189\n",
            "Speaker: 1580 SECS: 0.9485267 +- 0.0112\n",
            "Speaker: 1188 SECS: 0.9623372 +- 0.005\n",
            "Speaker: 121 SECS: 0.8994362 +- 0.0252\n",
            "Speaker: 1089 SECS: 0.9520942 +- 0.0265\n",
            "Speaker: 2300 SECS: 0.9292822 +- 0.0191\n",
            "Speaker: 1995 SECS: 0.9387368 +- 0.0232\n",
            "Speaker: 237 SECS: 0.9516346 +- 0.006\n",
            "Speaker: 908 SECS: 0.9088815 +- 0.0738\n",
            "Speaker: 1284 SECS: 0.9300431 +- 0.031\n",
            "All SECS: 0.93191886 +- 0.0089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM4Hc9vpnXlj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31585566-979d-4c8e-f705-6bb52f0c3e50"
      },
      "source": [
        "import scipy.stats as st\n",
        "\n",
        "reference_dataset_path = \"Test-Dataset/MLS_PT/references/\"\n",
        "\n",
        "Dataset_path = \"Test-Dataset/MLS_PT/Ground-Truth/\"\n",
        "\n",
        "def get_reference_sample(speaker_name, reference_wav_samples):\n",
        "  for n in reference_wav_samples:\n",
        "    if speaker_name == n.split(\"_\")[0]:\n",
        "      return n\n",
        "\n",
        "reference_wav_samples = os.listdir(reference_dataset_path)\n",
        "speakers_dir = os.listdir(Dataset_path)\n",
        "\n",
        "print(\"Portuguese Results:\")\n",
        "similarity = {}\n",
        "for speaker in speakers_dir:\n",
        "    speaker_name = speaker.split(\"_\")[0]\n",
        "    ref_name = get_reference_sample(speaker_name, reference_wav_samples)\n",
        "    ref_wav_path = os.path.join(reference_dataset_path, ref_name)\n",
        "    ref_emb = compute_emb(ref_wav_path)\n",
        "    for spk_file in os.listdir(os.path.join(Dataset_path, speaker)):\n",
        "      emb = compute_emb(os.path.join(Dataset_path, speaker, spk_file))\n",
        "      secs = cosine_similarity(ref_emb, emb)\n",
        "      print(secs, ref_wav_path, os.path.join(Dataset_path, speaker, spk_file))\n",
        "      #print(\"SECS:\", secs)\n",
        "      if speaker_name in similarity.keys():\n",
        "        similarity[speaker_name] += [secs]\n",
        "      else:\n",
        "        similarity[speaker_name] = [secs]\n",
        "\n",
        "\n",
        "\n",
        "all_secs = []         \n",
        "for key in similarity.keys():\n",
        "  speaker_secs = np.array(similarity[key]).mean()\n",
        "  low_b, high_b = st.t.interval(0.95, len(similarity[key])-1, loc=speaker_secs, scale=st.sem(similarity[key]))\n",
        "  confience_interval_more_less = round(speaker_secs-low_b, 4)\n",
        "  print(\"Speaker:\", key, \"SECS:\", speaker_secs, \"+-\", confience_interval_more_less)\n",
        "  all_secs += similarity[key]\n",
        "\n",
        "secs_all = np.array(all_secs).mean()\n",
        "low_b, high_b = st.t.interval(0.95, len(all_secs)-1, loc=secs_all, scale=st.sem(all_secs))\n",
        "confience_interval_more_less = round(secs_all-low_b, 4)\n",
        "print(\"All SECS:\", secs_all, \"+-\", confience_interval_more_less)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Portuguese Results:\n",
            "0.8311093 Test-Dataset/MLS_PT/references/5677_4807_000094.wav Test-Dataset/MLS_PT/Ground-Truth/5677/5677_4807_000309.wav\n",
            "0.9615841 Test-Dataset/MLS_PT/references/5677_4807_000094.wav Test-Dataset/MLS_PT/Ground-Truth/5677/5677_4807_000009.wav\n",
            "0.9291189 Test-Dataset/MLS_PT/references/5677_4807_000094.wav Test-Dataset/MLS_PT/Ground-Truth/5677/5677_4807_000051.wav\n",
            "0.9239801 Test-Dataset/MLS_PT/references/5677_4807_000094.wav Test-Dataset/MLS_PT/Ground-Truth/5677/5677_4807_000251.wav\n",
            "0.88626117 Test-Dataset/MLS_PT/references/5677_4807_000094.wav Test-Dataset/MLS_PT/Ground-Truth/5677/5677_4807_000098.wav\n",
            "0.82165724 Test-Dataset/MLS_PT/references/3050_2941_000034.wav Test-Dataset/MLS_PT/Ground-Truth/3050/3050_2941_000011.wav\n",
            "0.9269103 Test-Dataset/MLS_PT/references/3050_2941_000034.wav Test-Dataset/MLS_PT/Ground-Truth/3050/3050_2941_000002.wav\n",
            "0.9203015 Test-Dataset/MLS_PT/references/3050_2941_000034.wav Test-Dataset/MLS_PT/Ground-Truth/3050/3050_2941_000010.wav\n",
            "0.74028456 Test-Dataset/MLS_PT/references/3050_2941_000034.wav Test-Dataset/MLS_PT/Ground-Truth/3050/3050_2941_000003.wav\n",
            "0.93086404 Test-Dataset/MLS_PT/references/3050_2941_000034.wav Test-Dataset/MLS_PT/Ground-Truth/3050/3050_2941_000012.wav\n",
            "0.88097197 Test-Dataset/MLS_PT/references/12710_10229_000006.wav Test-Dataset/MLS_PT/Ground-Truth/12710/12710_10229_000003.wav\n",
            "0.92045 Test-Dataset/MLS_PT/references/12710_10229_000006.wav Test-Dataset/MLS_PT/Ground-Truth/12710/12710_10229_000004.wav\n",
            "0.9447256 Test-Dataset/MLS_PT/references/12710_10229_000006.wav Test-Dataset/MLS_PT/Ground-Truth/12710/12710_10229_000012.wav\n",
            "0.93639314 Test-Dataset/MLS_PT/references/12710_10229_000006.wav Test-Dataset/MLS_PT/Ground-Truth/12710/12710_10229_000008.wav\n",
            "0.92703736 Test-Dataset/MLS_PT/references/12710_10229_000006.wav Test-Dataset/MLS_PT/Ground-Truth/12710/12710_10229_000015.wav\n",
            "0.935667 Test-Dataset/MLS_PT/references/7925_6390_000006.wav Test-Dataset/MLS_PT/Ground-Truth/7925/7925_6390_000009.wav\n",
            "0.9443659 Test-Dataset/MLS_PT/references/7925_6390_000006.wav Test-Dataset/MLS_PT/Ground-Truth/7925/7925_6390_000008.wav\n",
            "0.9258051 Test-Dataset/MLS_PT/references/7925_6390_000006.wav Test-Dataset/MLS_PT/Ground-Truth/7925/7925_6390_000003.wav\n",
            "0.96563864 Test-Dataset/MLS_PT/references/7925_6390_000006.wav Test-Dataset/MLS_PT/Ground-Truth/7925/7925_6390_000004.wav\n",
            "0.94604415 Test-Dataset/MLS_PT/references/7925_6390_000006.wav Test-Dataset/MLS_PT/Ground-Truth/7925/7925_6390_000001.wav\n",
            "0.92614585 Test-Dataset/MLS_PT/references/9351_9018_000173.wav Test-Dataset/MLS_PT/Ground-Truth/9351/9351_9018_000354.wav\n",
            "0.97193074 Test-Dataset/MLS_PT/references/9351_9018_000173.wav Test-Dataset/MLS_PT/Ground-Truth/9351/9351_9018_000209.wav\n",
            "0.9498421 Test-Dataset/MLS_PT/references/9351_9018_000173.wav Test-Dataset/MLS_PT/Ground-Truth/9351/9351_9018_000231.wav\n",
            "0.89413446 Test-Dataset/MLS_PT/references/9351_9018_000173.wav Test-Dataset/MLS_PT/Ground-Truth/9351/9351_9018_000296.wav\n",
            "0.92198765 Test-Dataset/MLS_PT/references/9351_9018_000173.wav Test-Dataset/MLS_PT/Ground-Truth/9351/9351_9018_000194.wav\n",
            "0.90290034 Test-Dataset/MLS_PT/references/13069_13511_000007.wav Test-Dataset/MLS_PT/Ground-Truth/13069/13069_13511_000010.wav\n",
            "0.91529065 Test-Dataset/MLS_PT/references/13069_13511_000007.wav Test-Dataset/MLS_PT/Ground-Truth/13069/13069_13511_000005.wav\n",
            "0.9249415 Test-Dataset/MLS_PT/references/13069_13511_000007.wav Test-Dataset/MLS_PT/Ground-Truth/13069/13069_13511_000012.wav\n",
            "0.9115162 Test-Dataset/MLS_PT/references/13069_13511_000007.wav Test-Dataset/MLS_PT/Ground-Truth/13069/13069_13511_000013.wav\n",
            "0.9024621 Test-Dataset/MLS_PT/references/13069_13511_000007.wav Test-Dataset/MLS_PT/Ground-Truth/13069/13069_13511_000006.wav\n",
            "0.86586183 Test-Dataset/MLS_PT/references/12287_12742_000007.wav Test-Dataset/MLS_PT/Ground-Truth/12287/12287_12742_000001.wav\n",
            "0.91148365 Test-Dataset/MLS_PT/references/12287_12742_000007.wav Test-Dataset/MLS_PT/Ground-Truth/12287/12287_12742_000004.wav\n",
            "0.894204 Test-Dataset/MLS_PT/references/12287_12742_000007.wav Test-Dataset/MLS_PT/Ground-Truth/12287/12287_12742_000003.wav\n",
            "0.9058448 Test-Dataset/MLS_PT/references/12287_12742_000007.wav Test-Dataset/MLS_PT/Ground-Truth/12287/12287_12742_000010.wav\n",
            "0.9285387 Test-Dataset/MLS_PT/references/12287_12742_000007.wav Test-Dataset/MLS_PT/Ground-Truth/12287/12287_12742_000008.wav\n",
            "0.85743475 Test-Dataset/MLS_PT/references/12249_12765_000220.wav Test-Dataset/MLS_PT/Ground-Truth/12249/12249_12879_000708.wav\n",
            "0.80553335 Test-Dataset/MLS_PT/references/12249_12765_000220.wav Test-Dataset/MLS_PT/Ground-Truth/12249/12249_12879_000417.wav\n",
            "0.8482442 Test-Dataset/MLS_PT/references/12249_12765_000220.wav Test-Dataset/MLS_PT/Ground-Truth/12249/12249_12879_000387.wav\n",
            "0.82021093 Test-Dataset/MLS_PT/references/12249_12765_000220.wav Test-Dataset/MLS_PT/Ground-Truth/12249/12249_12879_000394.wav\n",
            "0.8243188 Test-Dataset/MLS_PT/references/12249_12765_000220.wav Test-Dataset/MLS_PT/Ground-Truth/12249/12249_12879_000544.wav\n",
            "0.96932656 Test-Dataset/MLS_PT/references/11995_10229_000007.wav Test-Dataset/MLS_PT/Ground-Truth/11995/11995_10229_000004.wav\n",
            "0.9592918 Test-Dataset/MLS_PT/references/11995_10229_000007.wav Test-Dataset/MLS_PT/Ground-Truth/11995/11995_10229_000005.wav\n",
            "0.9343411 Test-Dataset/MLS_PT/references/11995_10229_000007.wav Test-Dataset/MLS_PT/Ground-Truth/11995/11995_10229_000002.wav\n",
            "0.9424643 Test-Dataset/MLS_PT/references/11995_10229_000007.wav Test-Dataset/MLS_PT/Ground-Truth/11995/11995_10229_000003.wav\n",
            "0.95334655 Test-Dataset/MLS_PT/references/11995_10229_000007.wav Test-Dataset/MLS_PT/Ground-Truth/11995/11995_10229_000008.wav\n",
            "0.8886093 Test-Dataset/MLS_PT/references/4367_4272_000319.wav Test-Dataset/MLS_PT/Ground-Truth/4367/4367_4272_000607.wav\n",
            "0.91813374 Test-Dataset/MLS_PT/references/4367_4272_000319.wav Test-Dataset/MLS_PT/Ground-Truth/4367/4367_4272_000413.wav\n",
            "0.81454647 Test-Dataset/MLS_PT/references/4367_4272_000319.wav Test-Dataset/MLS_PT/Ground-Truth/4367/4367_4572_000124.wav\n",
            "0.755299 Test-Dataset/MLS_PT/references/4367_4272_000319.wav Test-Dataset/MLS_PT/Ground-Truth/4367/4367_5323_000002.wav\n",
            "0.8754333 Test-Dataset/MLS_PT/references/4367_4272_000319.wav Test-Dataset/MLS_PT/Ground-Truth/4367/4367_3698_000029.wav\n",
            "Speaker: 5677 SECS: 0.9064107 +- 0.0619\n",
            "Speaker: 3050 SECS: 0.8680035 +- 0.105\n",
            "Speaker: 12710 SECS: 0.92191553 +- 0.0306\n",
            "Speaker: 7925 SECS: 0.94350415 +- 0.0183\n",
            "Speaker: 9351 SECS: 0.9328081 +- 0.0366\n",
            "Speaker: 13069 SECS: 0.91142213 +- 0.0116\n",
            "Speaker: 12287 SECS: 0.9011866 +- 0.0289\n",
            "Speaker: 12249 SECS: 0.83114845 +- 0.0264\n",
            "Speaker: 11995 SECS: 0.9517541 +- 0.0171\n",
            "Speaker: 4367 SECS: 0.8504044 +- 0.081\n",
            "All SECS: 0.9018558 +- 0.0152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62CV9IJZt3sh"
      },
      "source": [
        "# Model+SCL\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCWdXthpt3ss"
      },
      "source": [
        "root_path = \"Audios/model+SCL/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDHA-4Ukt3ss"
      },
      "source": [
        "## Download and restore model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G38YWCdNt3st",
        "outputId": "3a6961b1-29e3-4ff8-c8fb-742d10b6b4ea"
      },
      "source": [
        "\n",
        "!gdown --id  1sgEjHt0lbPSEw9-FSbC_mBoOPwNi87YR -O $MODEL_PATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sgEjHt0lbPSEw9-FSbC_mBoOPwNi87YR\n",
            "To: /content/best_model.pth.tar\n",
            "380MB [00:03, 101MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IFnF8mzt3st"
      },
      "source": [
        "load_model(MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEDmEOrmt3sv"
      },
      "source": [
        "## English VCTK Test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMFld-Gtt3sv"
      },
      "source": [
        "Dataset_path = \"Test-Dataset/VCTK/VCTK_references/\"\n",
        "OUTPUT_WAV_PATH = os.path.join(root_path, \"English_VCTK_SECS/\")\n",
        "language_id = 0\n",
        "os.makedirs(OUTPUT_WAV_PATH, exist_ok=True)\n",
        "references = os.listdir(Dataset_path)\n",
        "\n",
        "compute_SECS_and_save_audios(references, Dataset_path, OUTPUT_WAV_PATH, language_id, English_test_sentences)\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhTXTugKt3su"
      },
      "source": [
        "## Portuguese MLS Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbwnOiV2t3sv"
      },
      "source": [
        "Dataset_path = \"Test-Dataset/MLS_PT/references/\"\n",
        "OUTPUT_WAV_PATH = os.path.join(root_path, \"Portuguese_MLS_SECS/\")\n",
        "\n",
        "language_id = 2\n",
        "os.makedirs(OUTPUT_WAV_PATH, exist_ok=True)\n",
        "\n",
        "references = os.listdir(Dataset_path)\n",
        "\n",
        "compute_SECS_and_save_audios(references, Dataset_path, OUTPUT_WAV_PATH, language_id, Portuguese_test_sentences)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkOpttNPt3sx"
      },
      "source": [
        "## English LibriTTS Test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVZbMkRdt3sx"
      },
      "source": [
        "Dataset_path = \"Test-Dataset/LibriTTS/LibriTTS_references/\"\n",
        "OUTPUT_WAV_PATH = os.path.join(root_path, \"English_LibriTTS_SECS/\")\n",
        "language_id = 0\n",
        "\n",
        "os.makedirs(OUTPUT_WAV_PATH, exist_ok=True)\n",
        "references = os.listdir(Dataset_path)\n",
        "\n",
        "compute_SECS_and_save_audios(references, Dataset_path, OUTPUT_WAV_PATH, language_id, English_test_sentences)\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D1UmQcOwvPW"
      },
      "source": [
        "# Download Audios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUr8Ee3fxGE2"
      },
      "source": [
        "OUT_ZIP_FILE = \"Audios-PT-FR-EN-VCTK+LibriTTS.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4AR7wbLwuPH"
      },
      "source": [
        "! zip -qq -r $OUT_ZIP_FILE Audios/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3jGdt0J0EOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de43abc6-846e-439d-da41-d3d595115a04"
      },
      "source": [
        "! du -sh $OUT_ZIP_FILE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24M\tAudios-PT-FR-EN-VCTK+LibriTTS.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "UVj6nSUtw5oM",
        "outputId": "97ff79d4-c27a-4a72-8a17-1df25880b8fb"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(OUT_ZIP_FILE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1c87c34b-8d8d-452a-a165-64eb44514578\", \"Audios-PT-FR-EN-VCTK+LibriTTS.zip\", 24505641)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}